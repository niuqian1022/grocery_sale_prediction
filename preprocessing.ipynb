{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import scipy\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read files, specity dtype to be short float for float columns\n",
    "train_sample = pd.read_csv('/home/sophia/Downloads/grocery_dataFiles/train.csv',                \n",
    "                    converters={'unit_sales': lambda u: float(u) if float(u) > 0 else 0})\n",
    "stores = pd.read_csv('/home/sophia/Downloads/grocery_dataFiles/stores.csv')\n",
    "items = pd.read_csv('/home/sophia/Downloads/grocery_dataFiles/items.csv')\n",
    "transactions = pd.read_csv('/home/sophia/Downloads/grocery_dataFiles/transactions.csv', \n",
    "                          dtype = {'transactions': 'int32'})\n",
    "oil = pd.read_csv('/home/sophia/Downloads/grocery_dataFiles/oil.csv', names = ['date', 'oil_price'], header=0,\n",
    "                 dtype = {'oil_price': 'float32'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('dimention of train_sample = ', train_sample.shape)\n",
    "print ('dimention of stores = ', stores.shape)\n",
    "print ('dimention of items = ', items.shape)\n",
    "print ('dimention of oil = ', oil.shape)\n",
    "print ('dimention of transactions = ', transactions.shape)\n",
    "\n",
    "print ('dtypes of train_sample = ', train_sample.dtypes)\n",
    "print ('dtypes of stores = ', stores.dtypes)\n",
    "print ('dtypes of items = ', items.dtypes)\n",
    "print ('dtypes of oil = ', oil.dtypes)\n",
    "print ('dtypes of transactions = ', transactions.dtypes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract features for the particular date(oil price, stores (e.g. locations and transactions)\n",
    "#and items (e.g. types) \n",
    "join1 = train_sample.join(oil.set_index('date'), on = 'date')\n",
    "join2 = join1.join(stores.set_index('store_nbr'), on = 'store_nbr', rsuffix = '_store')\n",
    "join3 = join2.join(items.set_index('item_nbr'), on = 'item_nbr', rsuffix = '_item')\n",
    "train = join3.join(transactions.set_index(['date','store_nbr']), on = ['date', 'store_nbr'], rsuffix = '_store')\n",
    "\n",
    "#Sort out holiday information\n",
    "holidays = pd.read_csv('/home/sophia/Downloads/grocery_dataFiles/holidays_events.csv')\n",
    "#If a holiday is transferred it is not celebrated\n",
    "holidays.loc[holidays['transferred'] == True, 'holiday_event'] = False\n",
    "holidays.loc[holidays['transferred'] != True, 'holiday_event'] = True\n",
    "#Work day is meant to make up \"bridage'\n",
    "holidays.loc[holidays['type'] == 'Work Day', 'holiday_event'] = False\n",
    "\n",
    "train = train.join(holidays.set_index('date'), on = 'date', rsuffix = '_holidays')\n",
    "train['holiday_loc_spec'] = False\n",
    "train['holiday_event'] = train['holiday_event'].astype('bool')\n",
    "\n",
    "# Step1: if it is National holiday, holiday_loc_spec is true \n",
    "train.loc[(train['holiday_event'] == True) & (train['locale'] == 'National'), 'holiday_loc_spec'] = True\n",
    "\n",
    "# Step2: if it is Regional holiday (state == locale_name), holiday_loc_spec is true \n",
    "train.loc[(train['holiday_event'] == True) & (train['locale'] == 'Regional') & (train['state'] == train['locale_name']), \n",
    "          'holiday_loc_spec'] = True\n",
    "\n",
    "# step3: if it is Local (locale_name == city), holiday_loc_spec is true \n",
    "train.loc[(train['holiday_event'] == True) & (train['locale'] == 'Local') & (train['city'] == train['locale_name']), \n",
    "     'holiday_loc_spec'] = True\n",
    "\n",
    "#print ('holidays: ', train.loc[train['holiday_loc_spec'] == True].shape[0])\n",
    "#print ('none-holidays: ', train.loc[train['holiday_loc_spec'] == False].shape[0])\n",
    "# Step 4: delete some columns (metadata about holidays)\n",
    "train = train.drop(columns= ['type_holidays', 'locale', 'locale_name', 'description', 'transferred'])\n",
    "# get date information (parsing date manually)\n",
    "train['year'] = pd.DatetimeIndex(train['date']).year.astype('object')\n",
    "train['month'] = pd.DatetimeIndex(train['date']).month.astype('object')\n",
    "train['dayofweek'] = pd.DatetimeIndex(train['date']).dayofweek.astype('object')\n",
    "\n",
    "#log transform the Y\n",
    "train['unit_sales_log'] = np.log(train['unit_sales'] + 1)\n",
    "\n",
    "#hand label onpromotions missing data as not-onpromotion\n",
    "\n",
    "train.loc[train.onpromotion.isnull(), 'onpromotion'] = False\n",
    "#train['onpromotion'] = train['onpromotion'].astype(bool)\n",
    "\n",
    "#fix dtypes so dummies variables can be generated\n",
    "train['perishable'] = train['perishable'].astype('bool')\n",
    "train['cluster'] = train['cluster'].astype('object')\n",
    "train['class'] = train['class'].astype('object')\n",
    "\n",
    "train_none_cate = train.loc[:, ['unit_sales_log', 'oil_price',\n",
    "                                'perishable','transactions', 'holiday_loc_spec', 'onpromotion']]\n",
    "train_cate = train.loc[:,['city', 'state', 'type', 'cluster', 'family', 'class', 'year', 'month', 'dayofweek']]\n",
    "train_cate = pd.get_dummies(train_cate, prefix = ['city', 'state', 'type', \n",
    "                                                  'cluster', 'family', 'class', 'year', 'month', 'dayofweek'])\n",
    "train = pd.concat([train_none_cate, train_cate], axis = 1)\n",
    "print (train.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('data_preprocessed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Imputer, StandardScaler\n",
    "X = train.loc[:, 'oil_price':]\n",
    "y = train.loc[:, 'unit_sales_log']\n",
    "\n",
    "print ('infomation about missing value before imputing')\n",
    "print (X.isnull().sum().sum())\n",
    "X.fillna(X.mean(), inplace=True)\n",
    "\n",
    "std = StandardScaler()\n",
    "std.fit(X.loc[:,['oil_price']].values)\n",
    "X['oil_price'] = std.transform(X.loc[:,['oil_price']].values)\n",
    "\n",
    "std = StandardScaler()\n",
    "std.fit(X.loc[:,['transactions']].values)\n",
    "X['transactions'] = std.transform(X.loc[:,['transactions']].values)\n",
    "print ('infomation about missing value after imputing')\n",
    "print (X.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (X['oil_price'].describe())\n",
    "print (X['transactions'].describe())\n",
    "print (X.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=1)\n",
    "\n",
    "model1 = SVR(kernel='linear', C=1)\n",
    "model2 = DecisionTreeRegressor(max_depth = 2)\n",
    "\n",
    "model1.fit(X_train, y_train)\n",
    "y_hat1_train = model1.predict(X_train)\n",
    "y_hat1_test = model1.predict(X_test)\n",
    "\n",
    "model2.fit(X_train, y_train)\n",
    "y_hat2_train = model2.predict(X_train)\n",
    "y_hat2_test = model1.predict(X_test)\n",
    "\n",
    "MSLE1_train = mean_squared_log_error(y_train, y_hat1_train)\n",
    "MSLE2_train = mean_squared_log_error(y_train, y_hat2_train)\n",
    "MSLE1_test = mean_squared_log_error(y_test, y_hat1_test)\n",
    "MSLE2_test = mean_squared_log_error(y_test, y_hat2_test)\n",
    "print ('train MSE, eva MSE, train MSE, eva MSE is ' , [MSLE1_train, MSLE2_train, MSLE1_train, MSLE2_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# work with holiday file, the goal is to determined if a particuar city of a store on a particular date\n",
    "# was celebrating holiday_event \n",
    "holidays = pd.read_csv('/home/sophia/Downloads/grocery_dataFiles/holidays_events.csv')\n",
    "list1 = list(holidays.locale_name.unique())\n",
    "list2 = list(stores.city.unique())\n",
    "print ('holiday locale names:', sorted(list1))\n",
    "print ('store city names:', sorted(list2))\n",
    "print ('states name: ', sorted(list(stores.state.unique())))\n",
    "n, bins, patches = plt.hist(holidays['type'], 50, normed=1, facecolor='green', alpha=0.75)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Step one: if holiday is transferred (only holiday has transferred examples, it was not celebrated, so labeled as not holiday_event\n",
    "# Step two: if holiday is not transferred, it remains as holiday_event\n",
    "# step three: Work Day are meant to make up Bridge, so not celebrated as holiday_event (it is all national) \n",
    "holidays.loc[holidays['transferred'] == True, 'holiday_event'] = False\n",
    "holidays.loc[holidays['transferred'] != True, 'holiday_event'] = True\n",
    "holidays.loc[holidays['type'] == 'Work Day', 'holiday_event'] = False\n",
    "holidays[holidays['type'] == 'Work Day']\n",
    "print (holidays.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now check the two things we have marked: holiday that has been transferred and work day that meant to make \n",
    "#up Bridge is labeled not holiday_event\n",
    "#plt.style.use('seaborn-white')\n",
    "plt.style.use('dark_background')\n",
    "holiday_locale_type = holidays.groupby(['type', 'holiday_event']).size()\n",
    "holiday_locale_type.unstack().plot(kind='bar',stacked=True, figsize=(12,10),  grid=False)\n",
    "plt.title('Stacked Barplot of holiday_event label against event type')\n",
    "plt.ylabel('Count of entries')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
