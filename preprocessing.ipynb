{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import scipy\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>item_nbr</th>\n",
       "      <th>unit_sales</th>\n",
       "      <th>onpromotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>25</td>\n",
       "      <td>103665</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>25</td>\n",
       "      <td>105574</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>25</td>\n",
       "      <td>105575</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>25</td>\n",
       "      <td>108079</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>25</td>\n",
       "      <td>108701</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id        date  store_nbr  item_nbr  unit_sales onpromotion\n",
       "0   0  2013-01-01         25    103665         7.0         NaN\n",
       "1   1  2013-01-01         25    105574         1.0         NaN\n",
       "2   2  2013-01-01         25    105575         2.0         NaN\n",
       "3   3  2013-01-01         25    108079         1.0         NaN\n",
       "4   4  2013-01-01         25    108701         1.0         NaN"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sample = pd.read_csv('/home/sophia/Downloads/grocery_dataFiles/train.csv', nrows = 1000000, \n",
    "                    dtype = {'onpromotion': str}, \n",
    "                    converters={'unit_sales': lambda u: float(u) if float(u) > 0 else 0})\n",
    "\n",
    "stores = pd.read_csv('/home/sophia/Downloads/grocery_dataFiles/stores.csv')\n",
    "items = pd.read_csv('/home/sophia/Downloads/grocery_dataFiles/items.csv')\n",
    "transactions = pd.read_csv('/home/sophia/Downloads/grocery_dataFiles/transactions.csv')\n",
    "oil = pd.read_csv('/home/sophia/Downloads/grocery_dataFiles/oil.csv')\n",
    "train_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dimention of train_sample =  (1000000, 6)\n",
      "dimention of stores =  (54, 5)\n",
      "dimention of items =  (4100, 4)\n",
      "dimention of oil =  (1218, 2)\n",
      "dimention of transactions =  (83488, 3)\n",
      "dtypes of train_sample =  id               int64\n",
      "date            object\n",
      "store_nbr        int64\n",
      "item_nbr         int64\n",
      "unit_sales     float64\n",
      "onpromotion     object\n",
      "dtype: object\n",
      "dtypes of stores =  store_nbr     int64\n",
      "city         object\n",
      "state        object\n",
      "type         object\n",
      "cluster       int64\n",
      "dtype: object\n",
      "dtypes of items =  item_nbr       int64\n",
      "family        object\n",
      "class          int64\n",
      "perishable     int64\n",
      "dtype: object\n",
      "dtypes of oil =  date           object\n",
      "dcoilwtico    float64\n",
      "dtype: object\n",
      "dtypes of transactions =  date            object\n",
      "store_nbr        int64\n",
      "transactions     int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print ('dimention of train_sample = ', train_sample.shape)\n",
    "print ('dimention of stores = ', stores.shape)\n",
    "print ('dimention of items = ', items.shape)\n",
    "print ('dimention of oil = ', oil.shape)\n",
    "print ('dimention of transactions = ', transactions.shape)\n",
    "\n",
    "print ('dtypes of train_sample = ', train_sample.dtypes)\n",
    "print ('dtypes of stores = ', stores.dtypes)\n",
    "print ('dtypes of items = ', items.dtypes)\n",
    "print ('dtypes of oil = ', oil.dtypes)\n",
    "print ('dtypes of transactions = ', transactions.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    1000000.000000\n",
      "mean           1.785632\n",
      "std            0.874475\n",
      "min            0.000000\n",
      "25%            1.098612\n",
      "50%            1.609438\n",
      "75%            2.302585\n",
      "max            8.560403\n",
      "Name: unit_sales_log, dtype: float64\n",
      "Index(['id', 'date', 'store_nbr', 'item_nbr', 'unit_sales', 'onpromotion',\n",
      "       'dcoilwtico', 'city', 'state', 'type', 'cluster', 'family', 'class',\n",
      "       'perishable', 'transactions', 'holiday_event', 'holiday_loc_spec',\n",
      "       'year', 'month', 'dayofweek', 'unit_sales_log'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#extract features for the particular date(oil price, stores (e.g. locations and transactions)\n",
    "#and items (e.g. types) \n",
    "join1 = train_sample.join(oil.set_index('date'), on = 'date')\n",
    "join2 = join1.join(stores.set_index('store_nbr'), on = 'store_nbr', rsuffix = '_store')\n",
    "join3 = join2.join(items.set_index('item_nbr'), on = 'item_nbr', rsuffix = '_item')\n",
    "train = join3.join(transactions.set_index(['date','store_nbr']), on = ['date', 'store_nbr'], rsuffix = '_store')\n",
    "\n",
    "#print (train_sample.dtypes)\n",
    "#print (train.dtypes)  \n",
    "\n",
    "holidays = pd.read_csv('/home/sophia/Downloads/grocery_dataFiles/holidays_events.csv')\n",
    "holidays.loc[holidays['transferred'] == True, 'holiday_event'] = False\n",
    "holidays.loc[holidays['transferred'] != True, 'holiday_event'] = True\n",
    "holidays.loc[holidays['type'] == 'Work Day', 'holiday_event'] = False\n",
    "\n",
    "train = train.join(holidays.set_index('date'), on = 'date', rsuffix = '_holidays')\n",
    "train['holiday_loc_spec'] = False\n",
    "train['holiday_event'] = train['holiday_event'].astype('bool')\n",
    "\n",
    "# Step1: if it is National holiday, holiday_loc_spec is true \n",
    "train.loc[(train['holiday_event'] == True) & (train['locale'] == 'National'), 'holiday_loc_spec'] = True\n",
    "\n",
    "# Step2: if it is Regional holiday (state == locale_name), holiday_loc_spec is true \n",
    "train.loc[(train['holiday_event'] == True) & (train['locale'] == 'Regional') & (train['state'] == train['locale_name']), \n",
    "          'holiday_loc_spec'] = True\n",
    "\n",
    "# step3: if it is Local (locale_name == city), holiday_loc_spec is true \n",
    "train.loc[(train['holiday_event'] == True) & (train['locale'] == 'Local') & (train['city'] == train['locale_name']), \n",
    "     'holiday_loc_spec'] = True\n",
    "\n",
    "#print ('holidays: ', train.loc[train['holiday_loc_spec'] == True].shape[0])\n",
    "#print ('none-holidays: ', train.loc[train['holiday_loc_spec'] == False].shape[0])\n",
    "#delete some columns (metadata about holidays)\n",
    "train = train.drop(columns= ['type_holidays', 'locale', 'locale_name', 'description', 'transferred'])\n",
    "train['year'] = pd.DatetimeIndex(train['date']).year.astype('object')\n",
    "train['month'] = pd.DatetimeIndex(train['date']).month.astype('object')\n",
    "train['dayofweek'] = pd.DatetimeIndex(train['date']).dayofweek.astype('object')\n",
    "train['unit_sales_log'] = np.log(train['unit_sales'] + 1)\n",
    "print (train['unit_sales_log'].describe())\n",
    "print (train.columns)\n",
    "#fix dtypes\n",
    "train['perishable'] = train['perishable'].astype('bool')\n",
    "#train['onpromotion'] = train['onpromotion'].astype('bool')\n",
    "train['cluster'] = train['cluster'].astype('object')\n",
    "train['class'] = train['class'].astype('object')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000000, 262)\n"
     ]
    }
   ],
   "source": [
    "train_none_cate = train.loc[:, ['unit_sales', 'unit_sales_log', 'dcoilwtico',\n",
    "                                'perishable','transactions', 'holiday_loc_spec', 'onpromotion']]\n",
    "train_cate = train.loc[:,['city', 'state', 'type', 'cluster', 'family', 'class', 'year', 'month', 'dayofweek']]\n",
    "train_cate = pd.get_dummies(train_cate, prefix = ['city', 'state', 'type', \n",
    "                                                  'cluster', 'family', 'class', 'year', 'month', 'dayofweek'])\n",
    "train = pd.concat([train_none_cate, train_cate], axis = 1)\n",
    "print (train_cate.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   unit_sales  unit_sales_log  dcoilwtico  perishable  transactions  \\\n",
      "0         7.0        2.079442         NaN        True           770   \n",
      "1         1.0        0.693147         NaN       False           770   \n",
      "2         2.0        1.098612         NaN       False           770   \n",
      "3         1.0        0.693147         NaN       False           770   \n",
      "4         1.0        0.693147         NaN        True           770   \n",
      "\n",
      "   holiday_loc_spec onpromotion  city_Quito  city_Salinas  city_Santo Domingo  \\\n",
      "0              True         NaN           0             1                   0   \n",
      "1              True         NaN           0             1                   0   \n",
      "2              True         NaN           0             1                   0   \n",
      "3              True         NaN           0             1                   0   \n",
      "4              True         NaN           0             1                   0   \n",
      "\n",
      "      ...       class_6810  class_6918  class_6920  class_7002  class_7016  \\\n",
      "0     ...                0           0           0           0           0   \n",
      "1     ...                0           0           0           0           0   \n",
      "2     ...                0           0           0           0           0   \n",
      "3     ...                0           0           0           0           0   \n",
      "4     ...                0           0           0           0           0   \n",
      "\n",
      "   class_7034  year_2013  month_1  dayofweek_1  dayofweek_2  \n",
      "0           0          1        1            1            0  \n",
      "1           0          1        1            1            0  \n",
      "2           0          1        1            1            0  \n",
      "3           0          1        1            1            0  \n",
      "4           0          1        1            1            0  \n",
      "\n",
      "[5 rows x 213 columns]\n"
     ]
    }
   ],
   "source": [
    "print (train.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infomation about missing value\n",
      "dcoilwtico            327733\n",
      "perishable                 0\n",
      "transactions               0\n",
      "holiday_loc_spec           0\n",
      "onpromotion                0\n",
      "city_Ambato                0\n",
      "city_Babahoyo              0\n",
      "city_Cayambe               0\n",
      "city_Cuenca                0\n",
      "city_Daule                 0\n",
      "city_El Carmen             0\n",
      "city_Esmeraldas            0\n",
      "city_Guaranda              0\n",
      "city_Guayaquil             0\n",
      "city_Ibarra                0\n",
      "city_Latacunga             0\n",
      "city_Loja                  0\n",
      "city_Machala               0\n",
      "city_Playas                0\n",
      "city_Quevedo               0\n",
      "city_Quito                 0\n",
      "city_Riobamba              0\n",
      "city_Salinas               0\n",
      "city_Santo Domingo         0\n",
      "state_Azuay                0\n",
      "state_Bolivar              0\n",
      "state_Chimborazo           0\n",
      "state_Cotopaxi             0\n",
      "state_El Oro               0\n",
      "state_Esmeraldas           0\n",
      "                       ...  \n",
      "class_3044                 0\n",
      "class_3046                 0\n",
      "class_3060                 0\n",
      "class_3090                 0\n",
      "class_4114                 0\n",
      "class_4122                 0\n",
      "class_4126                 0\n",
      "class_4214                 0\n",
      "class_4222                 0\n",
      "class_4252                 0\n",
      "class_4254                 0\n",
      "class_6155                 0\n",
      "class_6706                 0\n",
      "class_6806                 0\n",
      "class_6810                 0\n",
      "class_6824                 0\n",
      "class_6918                 0\n",
      "class_6920                 0\n",
      "class_7002                 0\n",
      "class_7016                 0\n",
      "class_7034                 0\n",
      "year_2013                  0\n",
      "month_1                    0\n",
      "dayofweek_0                0\n",
      "dayofweek_1                0\n",
      "dayofweek_2                0\n",
      "dayofweek_3                0\n",
      "dayofweek_4                0\n",
      "dayofweek_5                0\n",
      "dayofweek_6                0\n",
      "Length: 267, dtype: int64\n",
      "   dcoilwtico  perishable  transactions  holiday_loc_spec  onpromotion  \\\n",
      "0         NaN        True           770              True        False   \n",
      "1         NaN       False           770              True        False   \n",
      "2         NaN       False           770              True        False   \n",
      "3         NaN       False           770              True        False   \n",
      "4         NaN        True           770              True        False   \n",
      "\n",
      "   city_Ambato  city_Babahoyo  city_Cayambe  city_Cuenca  city_Daule  \\\n",
      "0            0              0             0            0           0   \n",
      "1            0              0             0            0           0   \n",
      "2            0              0             0            0           0   \n",
      "3            0              0             0            0           0   \n",
      "4            0              0             0            0           0   \n",
      "\n",
      "      ...       class_7034  year_2013  month_1  dayofweek_0  dayofweek_1  \\\n",
      "0     ...                0          1        1            0            1   \n",
      "1     ...                0          1        1            0            1   \n",
      "2     ...                0          1        1            0            1   \n",
      "3     ...                0          1        1            0            1   \n",
      "4     ...                0          1        1            0            1   \n",
      "\n",
      "   dayofweek_2  dayofweek_3  dayofweek_4  dayofweek_5  dayofweek_6  \n",
      "0            0            0            0            0            0  \n",
      "1            0            0            0            0            0  \n",
      "2            0            0            0            0            0  \n",
      "3            0            0            0            0            0  \n",
      "4            0            0            0            0            0  \n",
      "\n",
      "[5 rows x 267 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "after impute number of missing value:  0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dcoilwtico</th>\n",
       "      <th>perishable</th>\n",
       "      <th>transactions</th>\n",
       "      <th>holiday_loc_spec</th>\n",
       "      <th>onpromotion</th>\n",
       "      <th>city_Ambato</th>\n",
       "      <th>city_Babahoyo</th>\n",
       "      <th>city_Cayambe</th>\n",
       "      <th>city_Cuenca</th>\n",
       "      <th>city_Daule</th>\n",
       "      <th>...</th>\n",
       "      <th>class_7034</th>\n",
       "      <th>year_2013</th>\n",
       "      <th>month_1</th>\n",
       "      <th>dayofweek_0</th>\n",
       "      <th>dayofweek_1</th>\n",
       "      <th>dayofweek_2</th>\n",
       "      <th>dayofweek_3</th>\n",
       "      <th>dayofweek_4</th>\n",
       "      <th>dayofweek_5</th>\n",
       "      <th>dayofweek_6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>94.153816</td>\n",
       "      <td>1.0</td>\n",
       "      <td>770.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>94.153816</td>\n",
       "      <td>0.0</td>\n",
       "      <td>770.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>94.153816</td>\n",
       "      <td>0.0</td>\n",
       "      <td>770.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>94.153816</td>\n",
       "      <td>0.0</td>\n",
       "      <td>770.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>94.153816</td>\n",
       "      <td>1.0</td>\n",
       "      <td>770.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 267 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   dcoilwtico  perishable  transactions  holiday_loc_spec  onpromotion  \\\n",
       "0   94.153816         1.0         770.0               1.0          0.0   \n",
       "1   94.153816         0.0         770.0               1.0          0.0   \n",
       "2   94.153816         0.0         770.0               1.0          0.0   \n",
       "3   94.153816         0.0         770.0               1.0          0.0   \n",
       "4   94.153816         1.0         770.0               1.0          0.0   \n",
       "\n",
       "   city_Ambato  city_Babahoyo  city_Cayambe  city_Cuenca  city_Daule  \\\n",
       "0          0.0            0.0           0.0          0.0         0.0   \n",
       "1          0.0            0.0           0.0          0.0         0.0   \n",
       "2          0.0            0.0           0.0          0.0         0.0   \n",
       "3          0.0            0.0           0.0          0.0         0.0   \n",
       "4          0.0            0.0           0.0          0.0         0.0   \n",
       "\n",
       "      ...       class_7034  year_2013  month_1  dayofweek_0  dayofweek_1  \\\n",
       "0     ...              0.0        1.0      1.0          0.0          1.0   \n",
       "1     ...              0.0        1.0      1.0          0.0          1.0   \n",
       "2     ...              0.0        1.0      1.0          0.0          1.0   \n",
       "3     ...              0.0        1.0      1.0          0.0          1.0   \n",
       "4     ...              0.0        1.0      1.0          0.0          1.0   \n",
       "\n",
       "   dayofweek_2  dayofweek_3  dayofweek_4  dayofweek_5  dayofweek_6  \n",
       "0          0.0          0.0          0.0          0.0          0.0  \n",
       "1          0.0          0.0          0.0          0.0          0.0  \n",
       "2          0.0          0.0          0.0          0.0          0.0  \n",
       "3          0.0          0.0          0.0          0.0          0.0  \n",
       "4          0.0          0.0          0.0          0.0          0.0  \n",
       "\n",
       "[5 rows x 267 columns]"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = train.loc[:, 'dcoilwtico':]\n",
    "y = train.loc[:, 'unit_sales_log']\n",
    "\n",
    "X.loc[X['onpromotion'].isnull(), 'onpromotion'] = False\n",
    "X['onpromotion'] = X['onpromotion'].astype(bool)\n",
    "\n",
    "print ('infomation about missing value')\n",
    "print (X.isnull().sum())\n",
    "print (X.head())\n",
    "print (type(X))\n",
    "X_columns = X.columns\n",
    "\n",
    "from sklearn.preprocessing import Imputer, StandardScaler\n",
    "#imput NAN \n",
    "imp = Imputer(missing_values='NaN', strategy='mean', axis=0)\n",
    "X = imp.fit_transform(X)\n",
    "\n",
    "print('after impute number of missing value: ' , np.isnan(X).sum()) #after imputting it returns a np.array\n",
    "\n",
    "X = pd.DataFrame(X, columns = X_columns)\n",
    "X.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, Imputer\n",
    "std = StandardScaler()\n",
    "X.loc[:,'dcoilwtico'] = std.fit_transform(X.loc[:,['dcoilwtico']].values)\n",
    "X.loc[:,['transactions']] = std.fit_transform(X.loc[:,['transactions']].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    1.000000e+06\n",
      "mean     5.856023e-14\n",
      "std      1.000001e+00\n",
      "min     -1.379772e+00\n",
      "25%     -1.041769e+00\n",
      "50%      4.968951e-14\n",
      "75%      1.470713e-01\n",
      "max      2.256680e+00\n",
      "Name: dcoilwtico, dtype: float64\n",
      "       transactions\n",
      "count  1.000000e+06\n",
      "mean  -8.645884e-17\n",
      "std    1.000001e+00\n",
      "min   -1.390118e+00\n",
      "25%   -7.422046e-01\n",
      "50%   -2.928455e-01\n",
      "75%    5.337663e-01\n",
      "max    3.724216e+00\n"
     ]
    }
   ],
   "source": [
    "print (X['dcoilwtico'].describe())\n",
    "print (X.loc[:,['transactions']].describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=1)\n",
    "\n",
    "model1 = SVR(kernel='linear', C=1)\n",
    "model2 = DecisionTreeRegressor(max_depth = 2)\n",
    "\n",
    "model1.fit(X_train, y_train)\n",
    "y_hat1_train = model1.predict(X_train)\n",
    "y_hat1_test = model1.predict(X_test)\n",
    "\n",
    "model2.fit(X_train, y_train)\n",
    "y_hat2_train = model2.predict(X_train)\n",
    "y_hat2_test = model1.predict(X_test)\n",
    "\n",
    "MSLE1_train = mean_squared_log_error(y_train, y_hat1_train)\n",
    "MSLE2_train = mean_squared_log_error(y_train, y_hat2_train)\n",
    "MSLE1_test = mean_squared_log_error(y_test, y_hat1_test)\n",
    "MSLE2_test = mean_squared_log_error(y_test, y_hat2_test)\n",
    "print ('train MSE, eva MSE, train MSE, eva MSE is ' , [MSLE1_train, MSLE2_train, MSLE1_train, MSLE2_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# work with holiday file, the goal is to determined if a particuar city of a store on a particular date\n",
    "# was celebrating holiday_event \n",
    "holidays = pd.read_csv('/home/sophia/Downloads/grocery_dataFiles/holidays_events.csv')\n",
    "list1 = list(holidays.locale_name.unique())\n",
    "list2 = list(stores.city.unique())\n",
    "print ('holiday locale names:', sorted(list1))\n",
    "print ('store city names:', sorted(list2))\n",
    "print ('states name: ', sorted(list(stores.state.unique())))\n",
    "n, bins, patches = plt.hist(holidays['type'], 50, normed=1, facecolor='green', alpha=0.75)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Step one: if holiday is transferred (only holiday has transferred examples, it was not celebrated, so labeled as not holiday_event\n",
    "# Step two: if holiday is not transferred, it remains as holiday_event\n",
    "# step three: Work Day are meant to make up Bridge, so not celebrated as holiday_event (it is all national) \n",
    "holidays.loc[holidays['transferred'] == True, 'holiday_event'] = False\n",
    "holidays.loc[holidays['transferred'] != True, 'holiday_event'] = True\n",
    "holidays.loc[holidays['type'] == 'Work Day', 'holiday_event'] = False\n",
    "holidays[holidays['type'] == 'Work Day']\n",
    "print (holidays.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now check the two things we have marked: holiday that has been transferred and work day that meant to make \n",
    "#up Bridge is labeled not holiday_event\n",
    "#plt.style.use('seaborn-white')\n",
    "plt.style.use('dark_background')\n",
    "holiday_locale_type = holidays.groupby(['type', 'holiday_event']).size()\n",
    "holiday_locale_type.unstack().plot(kind='bar',stacked=True, figsize=(12,10),  grid=False)\n",
    "plt.title('Stacked Barplot of holiday_event label against event type')\n",
    "plt.ylabel('Count of entries')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
