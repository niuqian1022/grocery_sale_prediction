{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version 3.6.3 |Anaconda, Inc.| (default, Oct 13 2017, 12:02:49) \n",
      "[GCC 7.2.0]\n",
      "Pandas version 0.20.3\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import numpy as np\n",
    "import math\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import dates\n",
    "import seaborn as sns\n",
    "from dateutil.parser import parse \n",
    "from datetime import timedelta, date\n",
    "%matplotlib inline\n",
    "\n",
    "print('Python version ' + sys.version)\n",
    "print('Pandas version ' + pd.__version__)\n",
    "#print('Matplotlib version ' + matplotlib.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_sample = pd.read_csv('/home/sophia/Downloads/grocery_dataFiles/train.csv',                \n",
    "                         converters={'unit_sales': lambda u: np.log1p(float(u)) if float(u) > 0 else 0},\n",
    "                         parse_dates = ['date'],\n",
    "                         skiprows = 1,\n",
    "                         dtype = {'id': 'int32', 'store_nbr': 'int32', 'item_nbr': 'int32', 'onpromotion': 'bool'}, \n",
    "                         names = ['id', 'date', 'store_nbr', 'item_nbr', 'unit_sales', 'onpromotion'])\n",
    "print (train_sample.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction:\n",
    "There is always a delicate balance between over-stocking and under-stocking for retailers. Overstocking increases logistics and labor cost, while under-stocking under-feed your customers, and either way harms the profit in long run. The big question to ask in this project is how to predict sales for Favorita, a large supermarket retailer in using historical sales records.  What we have is records of unit sales magnitude for parcular stores, items and at a particular date for the past five years. In addition, there are some categorical features about the stores, items, and if the items/goods are on promotion or perishable. \n",
    "    \n",
    "A plot of total daily sales along all the record peroid indicate that year to year increasing trend as well as variation among years is quite remarkable, it is difficulat to  predict sales a few years and even a few months ahead using historical sales record (come back to this point later).  The first step is to load the most recent two-years record, and to understand the dataset through exploratory analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id                      int32\n",
      "date           datetime64[ns]\n",
      "store_nbr                int8\n",
      "item_nbr                int32\n",
      "unit_sales            float64\n",
      "onpromotion              bool\n",
      "dtype: object\n",
      "Dimention of 2016-17 training data: (71453276, 6)\n",
      "Date range of 2016-17 training data: 0   2015-08-16\n",
      "Name: date, dtype: datetime64[ns] - 71453275   2017-08-15\n",
      "Name: date, dtype: datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "train_1617 = pd.read_csv('train_1617.csv', parse_dates = ['date'], \n",
    "                        dtype = {'id': 'int32', 'store_nbr': 'int8', 'item_nbr': 'int32', 'onpromotion': 'bool'})\n",
    "print (train_1617.dtypes)\n",
    "#train_1617 = train_sample.loc[train_sample['date'] > parse('2015-08-15')]\n",
    "print ('Dimention of 2016-17 training data: {}'.format(train_1617.shape))\n",
    "print ('Date range of 2016-17 training data: {} - {}'.format(train_1617['date'][:1], train_1617['date'][-1:]))\n",
    "#train_1617.to_csv('train_1617.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory analysis:\n",
    "- Daily total sales along time for each store.\n",
    "- Biweekly pairwise correlation of daily sales for all stores (mean and std).\n",
    "- Features of stores and items. \n",
    "- Time series of continous variables: oil price and holiday.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "store_daily_sum = train_1617.groupby(['date', 'store_nbr'])['unit_sales'].sum()\n",
    "store_daily_sum = store_daily_sum.add_suffix('').reset_index()\n",
    "store_daily_sum['date'] = pd.DatetimeIndex(store_daily_sum['date'])\n",
    "store_daily_sum.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=3, ncols=5, sharex=True, sharey=True, figsize=(25,15))\n",
    "axes_list = [item for sublist in axes for item in sublist] \n",
    "\n",
    "for i in range(15):\n",
    "    df = store_daily_sum.loc[store_daily_sum['store_nbr'] == str(i+1)]\n",
    "    axes_list[i].plot(df['date'], df['unit_sales'])\n",
    "    axes_list[i].set_title(str('store' + df['store_nbr'].unique()))\n",
    "    axes_list[i].xaxis.set_major_locator(dates.MonthLocator())\n",
    "    axes_list[i].xaxis.set_major_formatter(dates.DateFormatter('\\n%m\\n%y'))\n",
    "    #plt.tight_layout()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# is a dataframe storeing daily sales data for each store, it is meant to by grouped by date\n",
    "def corr_matrix(store_nbr):\n",
    "    df = store_daily_sum.loc[store_daily_sum['store_nbr'] == str(store_nbr)]\n",
    "    df['group_label'] = df.groupby(pd.Grouper(key='date', freq='14D', axis=1)).ngroup()\n",
    "    df['dayofbiweek'] = [i for i in range(1, 15, 1)]*(df.shape[0]//14) + [i for i in range(1, (df.shape[0]%14) + 1, 1)]\n",
    "    df = df.pivot(index = 'dayofbiweek', columns = 'group_label', values = 'unit_sales')\n",
    "    return df.corr().as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count = 0\n",
    "for i in range(52):    \n",
    "    corr = corr_matrix(store_nbr = str(i+1))\n",
    "    if corr.shape == (53, 53):\n",
    "        count+=1\n",
    "print ('There are {} stores having complete cases of biweek correlation.'.format(count))\n",
    "\n",
    "corr_all_stores = np.zeros((52, 53, 53))\n",
    "for i in range(52):\n",
    "    corr = corr_matrix(store_nbr = str(i+1))\n",
    "    print \n",
    "    if corr.shape == (53, 53):\n",
    "        corr_all_stores[i::] = corr\n",
    "    else:\n",
    "        corr_all_stores[i::] = np.random.uniform(-1, 1, size = (53,53))\n",
    "print ('Shape of stacks of correlation matrix: {}'.format(corr_all_stores.shape))\n",
    "corr_mean = np.mean(corr_all_stores, axis = 0)\n",
    "corr_std = np.std(corr_all_stores, axis = 0)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "corr = corr_mean\n",
    "plt.figure(num=None, figsize=(6, 6), dpi=150, facecolor='w', edgecolor='k')\n",
    "mask = np.zeros_like(corr)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "with sns.axes_style(\"white\"):\n",
    "    ax1 = sns.heatmap(corr, mask = mask, square=True, xticklabels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "plt.figure(num=None, figsize=(6, 6), dpi=150, facecolor='w', edgecolor='k')\n",
    "corr_mean_rank = corr_mean\n",
    "corr_mean_rank[corr_mean_rank<0] = 0\n",
    "final_corr = np.zeros(corr_mean_rank.shape)\n",
    "for i in range(corr_mean_rank.shape[0]):\n",
    "    idx = np.argsort(-corr_mean_rank[i, i:])[:10]\n",
    "    final_corr[np.arange(i, corr_mean_rank.shape[1])[idx], i] = corr_mean_rank[i, i:][idx]    \n",
    "mask = np.zeros_like(corr)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "with sns.axes_style(\"white\"):\n",
    "    ax2 = sns.heatmap(final_corr, mask = mask, square=True, xticklabels=2)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "corr_mean_cutoff = corr_mean\n",
    "corr_mean_cutoff[corr_mean_cutoff<0.5] = 0\n",
    "plt.figure(num=None, figsize=(6, 6), dpi=150, facecolor='w', edgecolor='k')   \n",
    "mask = np.zeros_like(corr)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "with sns.axes_style(\"white\"):\n",
    "    ax1 = sns.heatmap(corr_mean, mask = mask, square=True, xticklabels=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory analysis for store and item features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stores = pd.read_csv('/home/sophia/Downloads/grocery_dataFiles/stores.csv', \n",
    "                     dtype = {'store_nbr' : 'int32', 'cluster': 'object'})\n",
    "items = pd.read_csv('/home/sophia/Downloads/grocery_dataFiles/items.csv', \n",
    "                    dtype = {'item_nbr' : 'int32', 'family': 'object', 'class': 'object', 'perishable': 'bool'})\n",
    "oil = pd.read_csv('/home/sophia/Downloads/grocery_dataFiles/oil.csv', names = ['date', 'oil_price'], header=0,\n",
    "                 dtype = {'oil_price': 'float32'}, parse_dates = ['date'])\n",
    "holidays = pd.read_csv('/home/sophia/Downloads/grocery_dataFiles/holidays_events.csv', parse_dates = ['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print ('dimention of stores = ', stores.shape)\n",
    "print ('dimention of items = ', items.shape)\n",
    "print ('dimention of oil = ', oil.shape)\n",
    "print (stores.head(3))\n",
    "print (items.head(3))\n",
    "print (oil.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What we learn from exploratory analysis:\n",
    "- How much data to use based on the biweekly daily sales correlation matrix? \n",
    "\n",
    "1) The correlation is only strong for adjacent biweek periods, and sales of Christmas and new year seems correlated with none of the other periods. This raise the limitation of the model, that very suitable for big holiday shopping seasons. Therefore training data including a few months' sale record should serve the purpose.\n",
    "\n",
    "2) Correlation between months across two years is very weak. Therefore training and validation set will be selected from adjacent biweek periods. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods\n",
    "### Data pre-processing\n",
    "\n",
    "1) Extract store (state/city/cluster) and item (family/type/class) features, as well as time-series variables (i.e. oil price, holiday, day of the week, day of the month).\n",
    "\n",
    "2) Impute missing data and transform and normalize continouis variables.\n",
    "\n",
    "3) Label encode categorical variables.\n",
    "\n",
    "\n",
    "### Feature engineering \n",
    "It is worthnoting that so far all the features are not closely related to target variable 'unit_sales', and most of them are categorical variables. In order to precisely predict 'unit_sales', statistical value (mean and std) of target variable over certain time period, can be used to predict target variable. Therefore an additional step to take is calculating statistical values for 'onpromotion' and 'unit_sales'. The intuation behind is to put suits of constrain on the prediction, for example using 3, 7 ,14 days' mean and std of 'unit_sales'of a particular item * store combination to predict the future 'unit_sale' of this item * store combination.\n",
    "\n",
    "### Assemble all features and develop train, val split\n",
    " \n",
    "train: 2017-07-01 - 2017-07-31;\n",
    "val: 2017-08-01 - 2017-08-15;\n",
    "(idelly multiple sets)\n",
    "\n",
    "### Modeling: \n",
    "Random forest and lgb\n",
    "\n",
    "### Prediction:\n",
    "Using data from 2017-07-16 to 2017-08-15 to generate prediction for test set posted on kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_17 = train_1617.loc[train_1617['date'] >= parse('2017-07-16')]\n",
    "train_17 = train_17.set_index([\"id\"])\n",
    "train_17.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_features(df):\n",
    "    print ('Assembling features ...')\n",
    "    df['month'] = pd.DatetimeIndex(df['date']).month.astype('object')\n",
    "    df['day'] = pd.DatetimeIndex(df['date']).day.astype('object')\n",
    "    df['dayofweek'] = pd.DatetimeIndex(df['date']).dayofweek.astype('object')\n",
    "\n",
    "    #extract features for the particular date (e.g. oil price, locations and transactions of the store, item features)\n",
    "    df = df.join(oil.set_index('date'), on = 'date')\n",
    "    df = df.join(stores.set_index('store_nbr'), on = 'store_nbr')\n",
    "    df = df.join(items.set_index('item_nbr'), on = 'item_nbr') # extract item features\n",
    "    \n",
    "    df = df.join(holidays.set_index('date'), on = 'date', rsuffix = '_h')\n",
    "    df.loc[df['type_h'].isnull(), 'type_h'] = False\n",
    "    df.loc[df['type_h'] == 'Holiday', 'type_h'] = True\n",
    "    df.loc[df['transferred'] == True, 'type_h'] = False\n",
    "\n",
    "    #Holiday Step1: if it is National holiday, holiday_loc_spec is true \n",
    "    df.loc[(df['type_h'] == True) & (df['locale'] == 'National'), 'type_h'] = True\n",
    "\n",
    "    #Holiday Step2: if it is Regional holiday (state == locale_name), holiday_loc_spec is true \n",
    "    df.loc[(df['type_h'] == True) & (df['locale'] == 'Regional') & (df['state'] == df['locale_name']), \n",
    "              'type_h'] = True\n",
    "\n",
    "    #Holiday tep3: if it is Local (locale_name == city), holiday_loc_spec is true \n",
    "    df.loc[(df['type_h'] == True) & (df['locale'] == 'Local') & (df['city'] == df['locale_name']), \n",
    "         'type_h'] = True\n",
    "    df['type_h'] = df['type_h'].astype('bool')\n",
    "\n",
    "    print ('holidays: ', df.loc[df['type_h'] == True].shape[0])\n",
    "    print ('none-holidays: ', df.loc[df['type_h'] == False].shape[0])\n",
    "\n",
    "    #Step 4: delete some columns (metadata about holidays)\n",
    "    df = df.drop(['locale', 'locale_name', 'description', 'transferred'], axis=1)\n",
    "    \n",
    "    #Imputing and log transform missing oil data\n",
    "    from sklearn.preprocessing import Imputer\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    print ('Imputing daily oil price ...')\n",
    "    print ('Missing oil price data: {}'.format(np.sum(df['oil_price'].isnull())))\n",
    "    imputer = Imputer()\n",
    "    df['oil_price'] = imputer.fit_transform(X = df['oil_price'].values.reshape(-1, 1))\n",
    "    print ('After imputing missing data: {}'.format(np.sum(df['oil_price'].isnull())))\n",
    "\n",
    "    df['oil_price_log'] = np.log(df['oil_price'] + 1)\n",
    "    scaler = StandardScaler()\n",
    "    df['oil_price_log_norm'] = scaler.fit_transform(X = df['oil_price_log'].values.reshape(-1, 1))\n",
    "    #print (df['oil_price_log_norm'].describe())\n",
    "    df = df.drop(['oil_price','oil_price_log'], axis = 1)\n",
    "    print (df.head(3))\n",
    "    #print (df.dtypes)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_17 = prepare_features(train_17)\n",
    "train_17 = train_17.set_index(['store_nbr', 'item_nbr', 'date'])\n",
    "train_17.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load test data here\n",
    "test = pd.read_csv('/home/sophia/Downloads/grocery_dataFiles/test.csv', parse_dates = ['date'],\n",
    "                  dtype = {'id': 'int32','date': 'object', 'store_nbr': 'int32', \n",
    "                           'item_nbr': 'int32', 'onpromotion': 'bool'})\n",
    "test = prepare_features(test)\n",
    "test = test.set_index(['store_nbr', 'item_nbr', 'date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  sklearn.preprocessing import LabelEncoder\n",
    "train_test_features = pd.concat([train_17, test], axis = 0)\n",
    "\n",
    "cate_features = ['city','state','type', 'cluster', 'family']\n",
    "noncate_features = ['month','day', 'dayofweek','onpromotion', 'class', 'perishable', 'type_h', 'oil_price_log_norm']\n",
    "data_cate = train_test_features[cate_features]\n",
    "data_noncate = train_test_features[noncate_features]\n",
    "#get onehot vector for category variables\n",
    "#data_cate = pd.get_dummies(data_cate, sparse = True)\n",
    "#just encode category variables (except class) with normalized int\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "for cate_col in cate_features:\n",
    "    data_cate[cate_col] = encoder.fit_transform(data_cate[cate_col].astype('str'))\n",
    "\n",
    "fullset_features = pd.concat([data_noncate, data_cate], axis = 1,\n",
    "                             join_axes=[data_noncate.index])\n",
    "obj_col = ['month', 'day', 'dayofweek', 'class']\n",
    "fullset_features[obj_col] = fullset_features[obj_col].astype('int16')\n",
    "\n",
    "#fullset_features.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_17['unit_sales']\n",
    "X_train = fullset_features.iloc[:train_17['unit_sales'].shape[0]]\n",
    "X_test = fullset_features.iloc[train_17['unit_sales'].shape[0]:]\n",
    "print (fullset_features.shape, X_train.shape, y_train.shape, X_test.shape)\n",
    "del fullset_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_coverage(df1, df2, col):    \n",
    "    listA = sorted(df1[col].unique())\n",
    "    listB = sorted(df2[col].unique())\n",
    "    if listA == listB:\n",
    "        print ('All the members in df2 are included in df1.')\n",
    "    else:\n",
    "        print ('Not all the members in df2 are included in df1.')\n",
    "        A = set(df1[col].unique())\n",
    "        B = set(df2[col].unique())\n",
    "        print ('there is {:.5}% new {} seen in df2 \\n'. format(((B-A)/len(A)) * 100, col)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_july = X_train.loc[(X_train['month'] == 7) & (X_train['day'] > 15)]\n",
    "X_val = X_train.loc[(X_train['month'] == 8)]\n",
    "y_train_july = y_train.iloc[:X_train_july.shape[0]]\n",
    "y_val = y_train.iloc[-X_val.shape[0]:]\n",
    "assert X_train_july.shape[0] == y_train_july.shape[0]\n",
    "assert X_val.shape[0] == y_val.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def NWRMSLE(y, pred, weights_vector):\n",
    "    weights = None\n",
    "    y = y.clip(0, y.max())\n",
    "    pred = pred.clip(0, pred.max())\n",
    "    weights = np.where(weights_vector == 1, 1.25, 1.0) \n",
    "    score = np.nansum(weights * ((pred - y) ** 2)) / weights.sum()\n",
    "    return np.sqrt(score)\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from time import time\n",
    "def train_predict(learner, X_train, y_train, X_val, y_val): \n",
    "    results = {}    \n",
    "    learner.fit(X_train, y_train)    \n",
    "    print (learner.feature_importances_)       \n",
    "        \n",
    "    pred_train = learner.predict(X_train)\n",
    "    pred_val = learner.predict(X_val)\n",
    "    \n",
    "    results['train_score'] = NWRMSLE(y_train, pred_train, X_train.perishable.values)\n",
    "    results['val_score'] = NWRMSLE(y_val, pred_val, X_val.perishable.values)    \n",
    "    \n",
    "    print ('Data trained on {}'.format(learner.__class__.__name__))\n",
    "    print ('traing and evaluation scores {},{}'.format(results['train_score'], results['val_score']))  \n",
    "    return results\n",
    "\n",
    "learner = RandomForestRegressor(n_estimators=500, max_features='sqrt', n_jobs=2)\n",
    "train_predict(learner, X_train_july, y_train_july, X_val_aug, y_val_aug)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read selected time period of training data to generate statistical features \n",
    "train_17 = train_1617.loc[train_1617['date'] >= parse('2017-01-01')]\n",
    "# load test data here\n",
    "test = pd.read_csv('/home/sophia/Downloads/grocery_dataFiles/test.csv', parse_dates = ['date'],\n",
    "                  dtype = {'id': 'int32','date': 'object', 'store_nbr': 'int32', \n",
    "                           'item_nbr': 'int32', 'onpromotion': 'bool'})\n",
    "# cast the day-by-day onpromotion (T/F) value for each particular store * item\n",
    "promo_train = train_17.set_index([\"store_nbr\", \"item_nbr\", \"date\"])[[\"onpromotion\"]].unstack(level=-1).fillna(False)\n",
    "promo_train.columns = promo_train.columns.get_level_values(1)\n",
    "\n",
    "promo_test = test.set_index(['store_nbr', 'item_nbr', 'date'])[[\"onpromotion\"]].unstack(level=-1).fillna(False)\n",
    "promo_test.columns = promo_test.columns.get_level_values(1)\n",
    "\n",
    "#reindex and fillna for text data because there will be new items seen in text but not in train so na is generated\n",
    "promo_test = promo_test.reindex(promo_train.index).fillna(False)\n",
    "promo = pd.concat([promo_train, promo_test], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sales_train = train_17.set_index([\"store_nbr\", \"item_nbr\", \"date\"])[[\"unit_sales\"]].unstack(level=-1).fillna(0)\n",
    "sales_train.columns = sales_train.columns.get_level_values(1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_timespan(df, st, minus, periods, freq='D'):\n",
    "    return df[pd.date_range(st - timedelta(days=minus), periods=periods, freq=freq)]\n",
    "\n",
    "def get_nearwd(date,b_date):\n",
    "    date_list = pd.date_range(date-timedelta(140),periods=21,freq='7D').date\n",
    "    result = date_list[date_list<=b_date][-1]\n",
    "    return result\n",
    "\n",
    "def prepare_dataset(t2017, is_train = True):\n",
    "    X = pd.DataFrame({\n",
    "        #if previous 14 days have any promo\n",
    "        \"promo_14days\": get_timespan(promo, t2017, 14, 14).sum(axis=1).values,         \n",
    "        \"promo_60days\": get_timespan(promo, t2017, 60, 60).sum(axis=1).values,\n",
    "        \"promo_140days\": get_timespan(promo, t2017, 140, 140).sum(axis=1).values,\n",
    "        #how many days in 14 days after not having any promotion\n",
    "        \"unpromo_14daysAfter\":\n",
    "        (1-get_timespan(promo, t2017+timedelta(14), 14, 14)).iloc[:,1:].sum(axis=1).values, \n",
    "    }, index = promo.index) #excluding the day itself so .iloc[:,1:]\n",
    "    \n",
    "    for i in range(7):\n",
    "        X[\"promo_{}\".format(i)] = promo[\n",
    "            t2017 + timedelta(days=i)].values.astype(np.uint8)\n",
    "        for j in [14,60,140]:\n",
    "            X[\"aft_promo_{}{}\".format(i,j)] = (promo[t2017 + timedelta(days=i)]-1).values.astype(np.uint8)\n",
    "            X[\"aft_promo_{}{}\".format(i,j)] = X[\"aft_promo_{}{}\".format(i,j)]*X['promo_{}'.format(i)]\n",
    "     \n",
    "    for i in range(7):\n",
    "        #X['mean_4_dow{}'.format(i)] = get_timespan(sales_train, t2017, 28-i, 4, freq='7D').mean(axis=1).values\n",
    "        #X['mean_12_dow{}'.format(i)] = get_timespan(sales_train, t2017, 84-i, 12, freq='7D').mean(axis=1).values\n",
    "        #X['mean_20_dow{}'.format(i)] = get_timespan(sales_train, t2017, 140-i, 20, freq='7D').mean(axis=1).values        \n",
    "        \n",
    "        date = get_nearwd(t2017+timedelta(i),t2017)\n",
    "        #ahead = (t2017-date).days\n",
    "        #if ahead!=0:\n",
    "        #    X['ahead0_{}'.format(i)] = get_timespan(sales_train, date+timedelta(ahead), ahead, ahead).mean(axis=1).values\n",
    "        #    X['ahead7_{}'.format(i)] = get_timespan(sales_train, date+timedelta(ahead), ahead+7, ahead+7).mean(axis=1).values\n",
    "        #X[\"day_1_{}1\".format(i)]= get_timespan(sales_train, date, 1, 1).values.ravel()\n",
    "        #X[\"day_1_{}2\".format(i)]= get_timespan(sales_train, date-timedelta(7), 1, 1).values.ravel()\n",
    "        for m in [3,7,14,30,60,140]:\n",
    "            X[\"mean_{}_{}1\".format(m,i)]= get_timespan(sales_train, date, m, m).\\\n",
    "                mean(axis=1).values\n",
    "            X[\"mean_{}_{}2\".format(m,i)]= get_timespan(sales_train, date-timedelta(7), m, m).\\\n",
    "                mean(axis=1).values\n",
    "    if is_train:\n",
    "        y = sales_train[pd.date_range(t2017, periods=16)].values\n",
    "        return X, y\n",
    "    return X\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing dataset...\n"
     ]
    }
   ],
   "source": [
    "print(\"Preparing dataset...\")\n",
    "\n",
    "t2017 = date(2017,7,15)\n",
    "X_l, y_l = [], []\n",
    "#get train_stat features calculated based on duration of (7/15 - 7/15 + 14 days)\n",
    "for i in range(3):\n",
    "    delta = timedelta(days=7 * i)\n",
    "    X_tmp, y_tmp = prepare_dataset(\n",
    "        t2017 + delta\n",
    "    )\n",
    "    X_l.append(X_tmp)  \n",
    "    y_l.append(y_tmp)\n",
    "X_train_stat = pd.concat(X_l, axis=0)\n",
    "y_train = np.concatenate(y_l, axis=0) # there will be 16 models for 16 date: july or aug 16-31\n",
    "\n",
    "del X_l, y_l\n",
    "t2017_val = date(2017, 7, 31)\n",
    "X_val_stat, y_val = prepare_dataset(t2017_val) \n",
    "X_test_stat = prepare_dataset(date(2017, 8, 16), is_train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(502545, 116) (502545, 16) (167515, 116) (167515, 16) (167515, 116)\n"
     ]
    }
   ],
   "source": [
    "print (X_train_stat.shape, y_train.shape, X_val_stat.shape, y_val.shape, X_test_stat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del promo, sales_train, train_17, train_1617 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "items['perishable'] = items['perishable'].astype('bool').fillna('False')\n",
    "encoder = LabelEncoder()\n",
    "col_toEncode = ['city','state','type', 'cluster'] \n",
    "for col in col_toEncode:\n",
    "    stores[col] = encoder.fit_transform(stores[col].astype('str'))\n",
    "col_toEncode = ['family', 'class']\n",
    "for col in col_toEncode:\n",
    "    items[col] = encoder.fit_transform(items[col].astype('str'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['store_nbr', 'city', 'state', 'type', 'cluster'], dtype='object')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stores.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_item_store_features(df):    \n",
    "    result = df.reset_index().join(stores.set_index('store_nbr'), on = 'store_nbr')\n",
    "    result = result.reset_index().join(items.set_index('item_nbr'), on = 'item_nbr')\n",
    "    result = result.set_index(['store_nbr', 'item_nbr'])\n",
    "    result = result.drop(['index'], axis = 1)\n",
    "    return result\n",
    "\n",
    "X_train = get_item_store_features(X_train_stat)\n",
    "X_val = get_item_store_features(X_val_stat)\n",
    "X_test = get_item_store_features(X_test_stat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>promo_140days</th>\n",
       "      <th>promo_14days</th>\n",
       "      <th>promo_60days</th>\n",
       "      <th>unpromo_14daysAfter</th>\n",
       "      <th>promo_0</th>\n",
       "      <th>aft_promo_014</th>\n",
       "      <th>aft_promo_060</th>\n",
       "      <th>aft_promo_0140</th>\n",
       "      <th>promo_1</th>\n",
       "      <th>aft_promo_114</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_60_62</th>\n",
       "      <th>mean_140_61</th>\n",
       "      <th>mean_140_62</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>type</th>\n",
       "      <th>cluster</th>\n",
       "      <th>family</th>\n",
       "      <th>class</th>\n",
       "      <th>perishable</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>store_nbr</th>\n",
       "      <th>item_nbr</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th>96995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.127077</td>\n",
       "      <td>0.094911</td>\n",
       "      <td>0.094911</td>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>64</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99197</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.618532</td>\n",
       "      <td>0.287785</td>\n",
       "      <td>0.265085</td>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>44</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103520</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.843241</td>\n",
       "      <td>0.806579</td>\n",
       "      <td>0.783879</td>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103665</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.070664</td>\n",
       "      <td>1.025455</td>\n",
       "      <td>1.031856</td>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>187</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105574</th>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.716859</td>\n",
       "      <td>1.781987</td>\n",
       "      <td>1.773880</td>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 123 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    promo_140days  promo_14days  promo_60days  \\\n",
       "store_nbr item_nbr                                              \n",
       "1         96995                 0             0             0   \n",
       "          99197                 0             0             0   \n",
       "          103520                0             0             0   \n",
       "          103665                0             0             0   \n",
       "          105574               30             0             0   \n",
       "\n",
       "                    unpromo_14daysAfter  promo_0  aft_promo_014  \\\n",
       "store_nbr item_nbr                                                \n",
       "1         96995                      13        0              0   \n",
       "          99197                      13        0              0   \n",
       "          103520                     13        0              0   \n",
       "          103665                     13        0              0   \n",
       "          105574                     13        0              0   \n",
       "\n",
       "                    aft_promo_060  aft_promo_0140  promo_1  aft_promo_114  \\\n",
       "store_nbr item_nbr                                                          \n",
       "1         96995                 0               0        0              0   \n",
       "          99197                 0               0        0              0   \n",
       "          103520                0               0        0              0   \n",
       "          103665                0               0        0              0   \n",
       "          105574                0               0        0              0   \n",
       "\n",
       "                       ...      mean_60_62  mean_140_61  mean_140_62  city  \\\n",
       "store_nbr item_nbr     ...                                                   \n",
       "1         96995        ...        0.127077     0.094911     0.094911    18   \n",
       "          99197        ...        0.618532     0.287785     0.265085    18   \n",
       "          103520       ...        0.843241     0.806579     0.783879    18   \n",
       "          103665       ...        1.070664     1.025455     1.031856    18   \n",
       "          105574       ...        1.716859     1.781987     1.773880    18   \n",
       "\n",
       "                    state  type  cluster  family  class  perishable  \n",
       "store_nbr item_nbr                                                   \n",
       "1         96995        12     3        4      12     64       False  \n",
       "          99197        12     3        4      12     44       False  \n",
       "          103520       12     3        4      12     17       False  \n",
       "          103665       12     3        4       5    187        True  \n",
       "          105574       12     3        4      12     31       False  \n",
       "\n",
       "[5 rows x 123 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del X_train_stat, X_val_stat, X_test_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.00254285  0.00184126  0.00231792  0.00209733  0.00684065  0.          0.\n",
      "  0.          0.00108641  0.          0.          0.          0.00090381\n",
      "  0.          0.          0.          0.00052063  0.          0.          0.\n",
      "  0.00048723  0.          0.          0.          0.00046105  0.          0.\n",
      "  0.          0.00036352  0.          0.          0.          0.02504953\n",
      "  0.00300765  0.07035944  0.00711245  0.06596959  0.0088748   0.05307327\n",
      "  0.00822968  0.01333634  0.00378787  0.00359839  0.00281756  0.00413083\n",
      "  0.00328941  0.00393313  0.0031399   0.01073394  0.00357393  0.01225143\n",
      "  0.00443816  0.00412681  0.00336567  0.00284227  0.00298071  0.00955587\n",
      "  0.00360406  0.01060357  0.00309643  0.01781069  0.00323823  0.01648382\n",
      "  0.00350636  0.00585065  0.00360737  0.00286884  0.00290016  0.00587725\n",
      "  0.0033014   0.01836175  0.00322638  0.02866302  0.00323848  0.01398794\n",
      "  0.00328032  0.00525684  0.00419702  0.00286623  0.0028921   0.0038273\n",
      "  0.00307479  0.02878804  0.00312458  0.02806896  0.00428028  0.01777963\n",
      "  0.00501769  0.00630403  0.00358751  0.00292042  0.00283338  0.00460529\n",
      "  0.00308684  0.03389644  0.00399361  0.04159521  0.00619941  0.03390453\n",
      "  0.00611183  0.00904396  0.00388397  0.00306727  0.00279979  0.00677782\n",
      "  0.00296588  0.05642478  0.00323561  0.05691575  0.00584329  0.04440439\n",
      "  0.0052686   0.01094173  0.00328806  0.00325177  0.00279255  0.00217327\n",
      "  0.00198667  0.00144977  0.00249841  0.00208264  0.00370419  0.00043986]\n",
      "Data trained on RandomForestRegressor\n",
      "traing and evaluation scores 0.21075555484650327,0.5802546367086151\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train_score': 0.21075555484650327, 'val_score': 0.5802546367086151}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def NWRMSLE(y, pred, weights_vector):\n",
    "    weights = None\n",
    "    y = y.clip(0, y.max())\n",
    "    pred = pred.clip(0, pred.max())\n",
    "    weights = np.where(weights_vector == 1, 1.25, 1.0) \n",
    "    score = np.nansum(weights * ((pred - y) ** 2)) / weights.sum()\n",
    "    return np.sqrt(score)\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from time import time\n",
    "def train_predict(learner, X_train, y_train, X_val, y_val): \n",
    "    results = {}    \n",
    "    learner.fit(X_train, y_train)    \n",
    "    print (learner.feature_importances_)       \n",
    "        \n",
    "    pred_train = learner.predict(X_train)\n",
    "    pred_val = learner.predict(X_val)\n",
    "    \n",
    "    results['train_score'] = NWRMSLE(y_train, pred_train, X_train.perishable.values)\n",
    "    results['val_score'] = NWRMSLE(y_val, pred_val, X_val.perishable.values)    \n",
    "    \n",
    "    print ('Data trained on {}'.format(learner.__class__.__name__))\n",
    "    print ('traing and evaluation scores {},{}'.format(results['train_score'], results['val_score']))  \n",
    "    return results\n",
    "\n",
    "learner = RandomForestRegressor(n_estimators=500, max_features='sqrt', n_jobs=2)\n",
    "train_predict(learner, X_train, y_train[:,0].reshape(X_train.shape[0]), \n",
    "              X_val, y_val[:,0].reshape(X_val.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\tvalid_0's rmse: 0.57736\n",
      "Early stopping, best iteration is:\n",
      "[103]\tvalid_0's rmse: 0.577317\n",
      "mean_14_01: 551746.71\n",
      "mean_30_01: 540393.32\n",
      "mean_30_61: 278660.22\n",
      "mean_60_01: 95525.33\n",
      "mean_7_01: 89903.32\n",
      "mean_3_31: 58112.84\n",
      "mean_3_32: 56403.16\n",
      "mean_60_41: 48592.61\n",
      "unpromo_14daysAfter: 36215.65\n",
      "mean_60_51: 25777.10\n",
      "mean_140_01: 18647.60\n",
      "class: 17566.43\n",
      "promo_14days: 14503.54\n",
      "type: 11246.42\n",
      "state: 10301.84\n",
      "mean_3_01: 9491.77\n",
      "mean_3_41: 6865.55\n",
      "city: 6683.73\n",
      "family: 6614.17\n",
      "cluster: 6290.82\n",
      "mean_140_12: 6233.14\n",
      "mean_3_22: 5568.01\n",
      "mean_30_31: 5265.93\n",
      "mean_30_32: 5095.61\n",
      "promo_60days: 4663.32\n",
      "mean_140_22: 4216.51\n",
      "promo_140days: 3906.25\n",
      "mean_3_42: 3641.36\n",
      "mean_60_31: 3454.44\n",
      "mean_7_12: 3408.74\n",
      "mean_30_22: 3256.57\n",
      "mean_140_61: 2971.09\n",
      "mean_60_22: 2810.89\n",
      "mean_60_21: 2809.77\n",
      "mean_3_12: 2705.44\n",
      "mean_3_52: 2460.70\n",
      "mean_3_21: 2443.89\n",
      "mean_60_12: 2306.76\n",
      "mean_30_21: 2263.91\n",
      "mean_3_11: 2251.76\n",
      "mean_3_51: 2170.12\n",
      "mean_3_61: 1960.37\n",
      "mean_60_42: 1872.37\n",
      "mean_3_02: 1869.19\n",
      "mean_14_12: 1709.67\n",
      "mean_3_62: 1705.21\n",
      "mean_140_42: 1418.69\n",
      "mean_140_32: 1344.57\n",
      "mean_30_12: 1321.48\n",
      "mean_140_31: 1312.35\n",
      "mean_60_32: 1246.78\n",
      "mean_7_22: 1246.70\n",
      "mean_140_51: 1239.53\n",
      "mean_7_32: 1200.11\n",
      "mean_60_52: 1088.92\n",
      "mean_7_51: 1054.83\n",
      "mean_7_42: 1054.41\n",
      "mean_140_62: 1019.91\n",
      "mean_140_11: 1009.04\n",
      "mean_14_02: 990.38\n",
      "mean_30_42: 975.44\n",
      "mean_30_11: 968.42\n",
      "mean_30_02: 966.04\n",
      "mean_7_61: 943.20\n",
      "mean_7_02: 925.42\n",
      "mean_7_11: 911.16\n",
      "mean_7_52: 891.84\n",
      "mean_60_61: 891.40\n",
      "mean_140_02: 874.64\n",
      "mean_14_22: 855.68\n",
      "mean_30_41: 828.58\n",
      "mean_14_62: 819.95\n",
      "mean_7_41: 815.12\n",
      "mean_7_31: 809.43\n",
      "mean_14_32: 765.89\n",
      "mean_14_11: 759.53\n",
      "mean_7_21: 737.51\n",
      "promo_4: 706.35\n",
      "mean_14_51: 705.27\n",
      "promo_3: 698.58\n",
      "mean_7_62: 696.56\n",
      "mean_14_31: 694.06\n",
      "mean_30_62: 682.38\n",
      "mean_14_52: 677.85\n",
      "mean_30_51: 664.35\n",
      "mean_14_61: 646.84\n",
      "promo_6: 603.90\n",
      "mean_140_21: 593.87\n",
      "mean_60_11: 560.21\n",
      "mean_140_52: 540.48\n",
      "promo_1: 534.60\n",
      "mean_60_62: 528.65\n",
      "mean_14_21: 521.85\n",
      "mean_14_42: 485.04\n",
      "mean_140_41: 455.31\n",
      "mean_14_41: 422.08\n",
      "mean_30_52: 410.41\n",
      "promo_0: 375.87\n",
      "mean_60_02: 374.89\n",
      "perishable: 368.75\n",
      "promo_5: 345.25\n",
      "promo_2: 330.61\n",
      "aft_promo_014: 0.00\n",
      "aft_promo_060: 0.00\n",
      "aft_promo_0140: 0.00\n",
      "aft_promo_114: 0.00\n",
      "aft_promo_160: 0.00\n",
      "aft_promo_1140: 0.00\n",
      "aft_promo_214: 0.00\n",
      "aft_promo_260: 0.00\n",
      "aft_promo_2140: 0.00\n",
      "aft_promo_314: 0.00\n",
      "aft_promo_360: 0.00\n",
      "aft_promo_3140: 0.00\n",
      "aft_promo_414: 0.00\n",
      "aft_promo_460: 0.00\n",
      "aft_promo_4140: 0.00\n",
      "aft_promo_514: 0.00\n",
      "aft_promo_560: 0.00\n",
      "aft_promo_5140: 0.00\n",
      "aft_promo_614: 0.00\n",
      "aft_promo_660: 0.00\n",
      "aft_promo_6140: 0.00\n",
      "Start predicting...\n",
      "The mrse of prediction is: 0.577317264096\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "def NWRMSLE(y, pred, weights_vector):\n",
    "    weights = None\n",
    "    y = y.clip(0, y.max())\n",
    "    pred = pred.clip(0, pred.max())\n",
    "    weights = np.where(weights_vector == 1, 1.25, 1.0) \n",
    "    score = np.nansum(weights * ((pred - y) ** 2)) / weights.sum()\n",
    "    return np.sqrt(score)\n",
    "\n",
    "# create dataset for lightgbm\n",
    "lgb_train = lgb.Dataset(X_train, y_train[:,0].reshape(X_train.shape[0]))\n",
    "                       #weight=X_train.perishable.values * 0.25 + 1)\n",
    "lgb_val = lgb.Dataset(X_val, y_val[:,0].reshape(X_val.shape[0]), reference=lgb_train)\n",
    "                     #weight=X_val.perishable.values * 0.25 + 1)\n",
    "\n",
    "MAX_ROUNDS = 1000\n",
    "# specify your configurations as a dict\n",
    "params = {\n",
    "    'task': 'train',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'metric': 'l2_root',\n",
    "    'num_leaves': 31,\n",
    "    'lambda_l1':0.1,\n",
    "    'num_data_in_leaf':200,\n",
    "    'learning_rate': 0.05,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'num_threads': 4\n",
    "}\n",
    "\n",
    "print('Start training...')\n",
    "# train\n",
    "gbm = lgb.train(params,\n",
    "                lgb_train,\n",
    "                num_boost_round=MAX_ROUNDS,\n",
    "                valid_sets= lgb_val,\n",
    "                early_stopping_rounds=50, \n",
    "                verbose_eval=100\n",
    "                )\n",
    "print(\"\\n\".join((\"%s: %.2f\" % x) for x in sorted(\n",
    "        zip(X_train.columns, bst.feature_importance(\"gain\")),\n",
    "        key=lambda x: x[1], reverse=True\n",
    "    )))\n",
    "\n",
    "print('Start predicting...')\n",
    "# predict\n",
    "y_pred = gbm.predict(X_val, num_iteration=gbm.best_iteration or MAX_ROUNDS)\n",
    "# eval\n",
    "print('The mrse of prediction is:', mean_squared_error(y_val[:,0], y_pred)**0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Step 1\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\ttraining's rmse: 0.5554\tvalid_1's rmse: 0.579688\n",
      "Early stopping, best iteration is:\n",
      "[89]\ttraining's rmse: 0.556544\tvalid_1's rmse: 0.579505\n",
      "mean_14_01: 884882.33\n",
      "mean_7_01: 841727.64\n",
      "mean_3_01: 115444.36\n",
      "mean_30_01: 29978.77\n",
      "promo_0: 27702.00\n",
      "mean_3_21: 19345.53\n",
      "mean_60_01: 11713.11\n",
      "promo_14days: 11688.34\n",
      "mean_3_22: 11210.60\n",
      "mean_60_21: 6128.22\n",
      "mean_140_01: 5023.23\n",
      "mean_60_22: 4009.32\n",
      "mean_30_11: 3941.00\n",
      "mean_3_51: 3683.19\n",
      "promo_2: 3067.40\n",
      "unpromo_14daysAfter: 2900.65\n",
      "mean_3_11: 2584.44\n",
      "mean_140_12: 2541.38\n",
      "mean_60_31: 2105.45\n",
      "mean_3_61: 2092.09\n",
      "mean_140_22: 1999.34\n",
      "promo_60days: 1808.75\n",
      "mean_30_21: 1806.62\n",
      "class: 1732.44\n",
      "type: 1685.20\n",
      "city: 1433.22\n",
      "cluster: 1368.83\n",
      "mean_140_32: 1368.66\n",
      "family: 1350.31\n",
      "mean_30_22: 1324.99\n",
      "mean_3_41: 1247.51\n",
      "state: 1226.04\n",
      "mean_3_32: 1098.26\n",
      "mean_30_12: 1092.58\n",
      "mean_60_12: 925.64\n",
      "mean_60_32: 901.09\n",
      "mean_7_61: 840.12\n",
      "mean_7_51: 821.35\n",
      "promo_140days: 814.84\n",
      "mean_60_42: 733.94\n",
      "mean_7_02: 723.08\n",
      "mean_3_31: 686.57\n",
      "mean_140_62: 650.70\n",
      "promo_1: 619.10\n",
      "mean_140_42: 602.63\n",
      "mean_3_42: 532.93\n",
      "mean_60_02: 518.72\n",
      "mean_3_12: 517.99\n",
      "mean_140_61: 490.77\n",
      "mean_14_02: 469.73\n",
      "mean_7_21: 453.63\n",
      "mean_3_02: 441.07\n",
      "perishable: 434.51\n",
      "mean_3_52: 379.30\n",
      "promo_3: 375.38\n",
      "mean_7_11: 369.27\n",
      "mean_14_51: 367.17\n",
      "mean_7_31: 366.71\n",
      "mean_60_11: 320.00\n",
      "mean_14_12: 317.54\n",
      "mean_30_61: 317.43\n",
      "mean_14_61: 295.88\n",
      "mean_7_22: 295.19\n",
      "mean_7_12: 292.37\n",
      "mean_14_21: 280.73\n",
      "mean_30_32: 260.91\n",
      "mean_7_32: 260.48\n",
      "mean_7_41: 249.01\n",
      "mean_7_52: 230.58\n",
      "mean_14_42: 219.99\n",
      "promo_4: 187.98\n",
      "mean_3_62: 175.70\n",
      "mean_14_62: 172.53\n",
      "mean_14_32: 171.56\n",
      "mean_7_42: 169.16\n",
      "mean_140_11: 161.48\n",
      "mean_30_51: 161.14\n",
      "mean_30_52: 147.33\n",
      "mean_14_41: 143.92\n",
      "mean_140_52: 136.71\n",
      "mean_14_31: 132.60\n",
      "mean_30_42: 100.60\n",
      "promo_5: 99.47\n",
      "promo_6: 96.36\n",
      "mean_14_11: 96.35\n",
      "mean_7_62: 78.33\n",
      "mean_14_22: 76.37\n",
      "mean_30_02: 64.97\n",
      "mean_140_31: 64.94\n",
      "mean_140_51: 61.18\n",
      "mean_60_51: 56.17\n",
      "mean_140_02: 49.18\n",
      "mean_60_61: 45.39\n",
      "mean_140_21: 43.43\n",
      "mean_14_52: 41.97\n",
      "mean_60_62: 35.52\n",
      "mean_60_41: 27.50\n",
      "mean_60_52: 24.18\n",
      "mean_30_41: 14.94\n",
      "mean_30_62: 9.24\n",
      "mean_140_41: 8.26\n",
      "aft_promo_014: 0.00\n",
      "aft_promo_060: 0.00\n",
      "aft_promo_0140: 0.00\n",
      "aft_promo_114: 0.00\n",
      "aft_promo_160: 0.00\n",
      "aft_promo_1140: 0.00\n",
      "aft_promo_214: 0.00\n",
      "aft_promo_260: 0.00\n",
      "aft_promo_2140: 0.00\n",
      "aft_promo_314: 0.00\n",
      "aft_promo_360: 0.00\n",
      "aft_promo_3140: 0.00\n",
      "aft_promo_414: 0.00\n",
      "aft_promo_460: 0.00\n",
      "aft_promo_4140: 0.00\n",
      "aft_promo_514: 0.00\n",
      "aft_promo_560: 0.00\n",
      "aft_promo_5140: 0.00\n",
      "aft_promo_614: 0.00\n",
      "aft_promo_660: 0.00\n",
      "aft_promo_6140: 0.00\n",
      "mean_30_31: 0.00\n",
      "==================================================\n",
      "Step 2\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\ttraining's rmse: 0.573285\tvalid_1's rmse: 0.601288\n",
      "Early stopping, best iteration is:\n",
      "[54]\ttraining's rmse: 0.581907\tvalid_1's rmse: 0.600635\n",
      "mean_14_01: 1095421.59\n",
      "mean_7_01: 731748.29\n",
      "mean_3_31: 61255.15\n",
      "mean_30_01: 41358.98\n",
      "promo_1: 32463.65\n",
      "mean_3_32: 27272.88\n",
      "mean_3_01: 17341.51\n",
      "mean_30_21: 12400.55\n",
      "mean_140_01: 10431.58\n",
      "mean_60_31: 9968.52\n",
      "promo_14days: 9467.94\n",
      "mean_60_41: 9133.52\n",
      "mean_30_22: 6747.67\n",
      "type: 6603.83\n",
      "mean_60_01: 6116.37\n",
      "city: 5256.90\n",
      "unpromo_14daysAfter: 4798.90\n",
      "mean_30_31: 4715.69\n",
      "state: 4470.20\n",
      "cluster: 4349.16\n",
      "mean_60_51: 4340.21\n",
      "mean_60_42: 2744.88\n",
      "mean_3_41: 2705.98\n",
      "mean_140_22: 2338.71\n",
      "mean_60_22: 2233.07\n",
      "class: 2062.71\n",
      "mean_140_12: 1965.66\n",
      "promo_0: 1947.75\n",
      "promo_60days: 1871.11\n",
      "family: 1569.10\n",
      "promo_2: 1511.22\n",
      "mean_3_51: 1284.08\n",
      "mean_30_61: 1240.39\n",
      "mean_140_32: 1063.57\n",
      "mean_3_22: 1013.93\n",
      "mean_60_52: 801.47\n",
      "mean_3_52: 760.75\n",
      "mean_140_11: 749.04\n",
      "mean_3_11: 694.89\n",
      "mean_140_42: 658.83\n",
      "mean_60_32: 618.91\n",
      "promo_4: 580.02\n",
      "mean_7_11: 570.50\n",
      "mean_140_52: 530.18\n",
      "mean_7_51: 511.36\n",
      "mean_7_41: 478.73\n",
      "mean_7_21: 429.23\n",
      "mean_7_31: 427.38\n",
      "mean_30_52: 404.97\n",
      "mean_60_61: 346.47\n",
      "mean_3_12: 333.77\n",
      "mean_14_12: 327.44\n",
      "promo_140days: 306.07\n",
      "mean_3_21: 290.55\n",
      "promo_3: 289.77\n",
      "mean_60_12: 283.77\n",
      "mean_140_41: 261.18\n",
      "mean_3_42: 242.06\n",
      "perishable: 238.14\n",
      "mean_140_21: 218.26\n",
      "mean_3_61: 208.45\n",
      "mean_30_32: 208.28\n",
      "mean_140_51: 204.04\n",
      "mean_3_02: 181.06\n",
      "mean_14_41: 179.63\n",
      "mean_30_12: 177.79\n",
      "mean_14_22: 163.27\n",
      "mean_60_21: 157.30\n",
      "mean_7_32: 124.80\n",
      "mean_30_11: 114.28\n",
      "mean_7_52: 106.37\n",
      "mean_7_42: 104.26\n",
      "mean_30_42: 98.71\n",
      "mean_30_62: 87.27\n",
      "mean_7_12: 83.57\n",
      "mean_30_41: 82.38\n",
      "mean_60_62: 74.30\n",
      "mean_14_61: 70.38\n",
      "mean_14_32: 70.02\n",
      "mean_140_62: 58.09\n",
      "mean_3_62: 57.69\n",
      "mean_7_61: 56.52\n",
      "promo_6: 38.50\n",
      "mean_7_02: 37.70\n",
      "mean_7_22: 35.41\n",
      "mean_14_11: 33.16\n",
      "mean_14_31: 27.13\n",
      "promo_5: 25.50\n",
      "mean_14_52: 25.15\n",
      "mean_7_62: 24.61\n",
      "mean_140_31: 24.15\n",
      "mean_30_02: 21.02\n",
      "mean_14_42: 17.18\n",
      "aft_promo_014: 0.00\n",
      "aft_promo_060: 0.00\n",
      "aft_promo_0140: 0.00\n",
      "aft_promo_114: 0.00\n",
      "aft_promo_160: 0.00\n",
      "aft_promo_1140: 0.00\n",
      "aft_promo_214: 0.00\n",
      "aft_promo_260: 0.00\n",
      "aft_promo_2140: 0.00\n",
      "aft_promo_314: 0.00\n",
      "aft_promo_360: 0.00\n",
      "aft_promo_3140: 0.00\n",
      "aft_promo_414: 0.00\n",
      "aft_promo_460: 0.00\n",
      "aft_promo_4140: 0.00\n",
      "aft_promo_514: 0.00\n",
      "aft_promo_560: 0.00\n",
      "aft_promo_5140: 0.00\n",
      "aft_promo_614: 0.00\n",
      "aft_promo_660: 0.00\n",
      "aft_promo_6140: 0.00\n",
      "mean_14_02: 0.00\n",
      "mean_60_02: 0.00\n",
      "mean_140_02: 0.00\n",
      "mean_60_11: 0.00\n",
      "mean_14_21: 0.00\n",
      "mean_14_51: 0.00\n",
      "mean_30_51: 0.00\n",
      "mean_14_62: 0.00\n",
      "mean_140_61: 0.00\n",
      "==================================================\n",
      "Step 3\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\ttraining's rmse: 0.576232\tvalid_1's rmse: 0.587237\n",
      "[200]\ttraining's rmse: 0.569042\tvalid_1's rmse: 0.586376\n",
      "Early stopping, best iteration is:\n",
      "[234]\ttraining's rmse: 0.566841\tvalid_1's rmse: 0.586272\n",
      "mean_14_01: 1006767.85\n",
      "mean_7_01: 580782.69\n",
      "mean_30_01: 53091.21\n",
      "promo_2: 31823.13\n",
      "mean_3_01: 17960.40\n",
      "mean_60_61: 12416.50\n",
      "promo_14days: 12403.06\n",
      "mean_3_41: 10458.91\n",
      "class: 6923.25\n",
      "mean_30_61: 6464.60\n",
      "mean_3_42: 5502.92\n",
      "unpromo_14daysAfter: 5225.90\n",
      "mean_140_01: 5141.04\n",
      "mean_60_01: 5075.38\n",
      "promo_0: 4554.39\n",
      "mean_60_51: 4278.83\n",
      "mean_14_12: 2915.70\n",
      "mean_3_52: 2697.64\n",
      "mean_30_41: 2657.37\n",
      "mean_30_31: 2573.78\n",
      "mean_3_51: 2406.72\n",
      "promo_60days: 2209.72\n",
      "family: 2130.38\n",
      "mean_60_41: 2047.16\n",
      "mean_140_61: 2043.01\n",
      "mean_60_42: 1889.69\n",
      "mean_3_61: 1734.50\n",
      "mean_3_11: 1702.23\n",
      "mean_30_42: 1694.58\n",
      "mean_3_12: 1609.49\n",
      "mean_140_12: 1518.25\n",
      "mean_60_52: 1517.31\n",
      "mean_60_62: 1517.20\n",
      "mean_140_31: 1486.20\n",
      "mean_3_31: 1387.61\n",
      "city: 1372.32\n",
      "mean_3_21: 1365.40\n",
      "mean_7_51: 1217.45\n",
      "mean_3_22: 1166.87\n",
      "mean_140_42: 1146.54\n",
      "mean_3_02: 1139.85\n",
      "mean_140_22: 1119.29\n",
      "mean_3_32: 1083.10\n",
      "mean_7_31: 999.38\n",
      "promo_3: 972.75\n",
      "promo_140days: 949.18\n",
      "promo_4: 944.79\n",
      "mean_3_62: 920.68\n",
      "mean_7_61: 878.62\n",
      "mean_7_12: 874.52\n",
      "mean_7_11: 839.08\n",
      "mean_60_12: 806.48\n",
      "mean_30_32: 805.39\n",
      "mean_7_41: 769.67\n",
      "mean_7_22: 724.87\n",
      "promo_1: 722.16\n",
      "cluster: 707.82\n",
      "mean_140_32: 705.94\n",
      "state: 703.70\n",
      "mean_14_22: 673.37\n",
      "type: 672.44\n",
      "mean_60_32: 665.25\n",
      "mean_7_52: 645.39\n",
      "mean_30_11: 636.65\n",
      "mean_30_12: 627.44\n",
      "mean_7_02: 560.54\n",
      "mean_14_11: 488.16\n",
      "promo_5: 484.30\n",
      "mean_7_62: 475.39\n",
      "mean_7_32: 463.83\n",
      "perishable: 457.71\n",
      "mean_7_21: 443.09\n",
      "mean_14_41: 434.87\n",
      "mean_14_61: 408.52\n",
      "mean_30_52: 397.08\n",
      "mean_30_02: 383.77\n",
      "mean_30_22: 366.31\n",
      "mean_14_31: 361.85\n",
      "mean_14_62: 358.11\n",
      "mean_7_42: 356.78\n",
      "mean_14_21: 356.31\n",
      "mean_14_42: 333.36\n",
      "mean_140_02: 328.60\n",
      "mean_60_11: 314.15\n",
      "mean_30_62: 313.87\n",
      "mean_14_32: 313.08\n",
      "mean_30_51: 312.53\n",
      "mean_140_51: 309.98\n",
      "mean_140_52: 308.18\n",
      "mean_14_02: 303.37\n",
      "mean_140_11: 277.29\n",
      "mean_14_52: 276.28\n",
      "mean_60_22: 265.29\n",
      "mean_30_21: 265.23\n",
      "mean_60_31: 265.06\n",
      "mean_14_51: 225.45\n",
      "mean_60_02: 204.82\n",
      "mean_140_21: 151.22\n",
      "mean_140_62: 135.63\n",
      "mean_140_41: 133.46\n",
      "mean_60_21: 109.77\n",
      "promo_6: 22.81\n",
      "aft_promo_014: 0.00\n",
      "aft_promo_060: 0.00\n",
      "aft_promo_0140: 0.00\n",
      "aft_promo_114: 0.00\n",
      "aft_promo_160: 0.00\n",
      "aft_promo_1140: 0.00\n",
      "aft_promo_214: 0.00\n",
      "aft_promo_260: 0.00\n",
      "aft_promo_2140: 0.00\n",
      "aft_promo_314: 0.00\n",
      "aft_promo_360: 0.00\n",
      "aft_promo_3140: 0.00\n",
      "aft_promo_414: 0.00\n",
      "aft_promo_460: 0.00\n",
      "aft_promo_4140: 0.00\n",
      "aft_promo_514: 0.00\n",
      "aft_promo_560: 0.00\n",
      "aft_promo_5140: 0.00\n",
      "aft_promo_614: 0.00\n",
      "aft_promo_660: 0.00\n",
      "aft_promo_6140: 0.00\n",
      "==================================================\n",
      "Step 4\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\ttraining's rmse: 0.582738\tvalid_1's rmse: 0.597572\n",
      "Early stopping, best iteration is:\n",
      "[53]\ttraining's rmse: 0.58904\tvalid_1's rmse: 0.594824\n",
      "mean_14_01: 719618.08\n",
      "mean_7_01: 519210.57\n",
      "mean_30_01: 298698.67\n",
      "promo_3: 51008.65\n",
      "mean_3_01: 26700.32\n",
      "mean_3_61: 14752.18\n",
      "mean_60_01: 13697.27\n",
      "promo_14days: 12414.29\n",
      "mean_30_61: 10505.43\n",
      "mean_140_01: 6642.96\n",
      "unpromo_14daysAfter: 4957.40\n",
      "mean_30_41: 4512.31\n",
      "mean_3_62: 4074.88\n",
      "mean_3_51: 3577.24\n",
      "mean_60_61: 3554.97\n",
      "type: 3228.02\n",
      "promo_0: 2938.89\n",
      "mean_140_32: 2868.73\n",
      "mean_140_12: 2687.58\n",
      "promo_4: 2548.79\n",
      "family: 2514.75\n",
      "mean_30_42: 2359.14\n",
      "mean_140_22: 2111.43\n",
      "mean_3_41: 1986.35\n",
      "class: 1934.52\n",
      "mean_14_12: 1681.23\n",
      "promo_60days: 1378.88\n",
      "mean_60_52: 1351.12\n",
      "mean_60_12: 1291.79\n",
      "mean_60_42: 1290.39\n",
      "mean_60_41: 1256.04\n",
      "mean_30_52: 1213.93\n",
      "mean_30_51: 1110.93\n",
      "mean_3_52: 995.39\n",
      "mean_60_22: 898.07\n",
      "city: 843.75\n",
      "mean_140_42: 771.81\n",
      "mean_3_31: 757.52\n",
      "mean_3_42: 731.40\n",
      "mean_60_51: 677.85\n",
      "mean_3_21: 662.02\n",
      "mean_60_62: 656.36\n",
      "mean_30_62: 651.50\n",
      "mean_7_51: 648.90\n",
      "mean_30_12: 610.38\n",
      "mean_7_21: 577.89\n",
      "mean_3_12: 436.37\n",
      "mean_3_22: 380.74\n",
      "mean_7_41: 360.00\n",
      "mean_140_51: 346.75\n",
      "promo_140days: 326.82\n",
      "mean_7_02: 308.51\n",
      "cluster: 243.74\n",
      "mean_140_52: 232.02\n",
      "mean_7_22: 227.69\n",
      "mean_7_52: 222.01\n",
      "mean_60_31: 206.98\n",
      "mean_7_11: 199.08\n",
      "mean_140_11: 198.79\n",
      "mean_3_11: 198.40\n",
      "mean_7_61: 178.31\n",
      "mean_7_31: 176.22\n",
      "mean_7_12: 175.40\n",
      "promo_5: 167.34\n",
      "mean_14_02: 151.49\n",
      "mean_60_11: 149.65\n",
      "mean_3_02: 144.63\n",
      "mean_14_22: 142.21\n",
      "mean_30_11: 129.14\n",
      "mean_3_32: 127.26\n",
      "mean_14_31: 126.84\n",
      "promo_2: 123.41\n",
      "perishable: 121.18\n",
      "mean_7_32: 118.51\n",
      "mean_140_02: 115.14\n",
      "promo_1: 115.03\n",
      "mean_30_22: 113.53\n",
      "mean_14_32: 99.07\n",
      "mean_140_61: 85.26\n",
      "mean_7_42: 84.22\n",
      "mean_14_11: 71.60\n",
      "mean_60_21: 71.34\n",
      "mean_14_61: 70.33\n",
      "mean_14_42: 67.06\n",
      "mean_140_31: 66.47\n",
      "state: 55.25\n",
      "mean_14_41: 42.71\n",
      "mean_30_21: 41.87\n",
      "mean_140_62: 40.26\n",
      "mean_14_21: 38.65\n",
      "mean_140_21: 32.85\n",
      "mean_30_31: 27.87\n",
      "mean_30_32: 25.94\n",
      "mean_14_62: 22.22\n",
      "mean_14_52: 14.46\n",
      "mean_140_41: 12.64\n",
      "aft_promo_014: 0.00\n",
      "aft_promo_060: 0.00\n",
      "aft_promo_0140: 0.00\n",
      "aft_promo_114: 0.00\n",
      "aft_promo_160: 0.00\n",
      "aft_promo_1140: 0.00\n",
      "aft_promo_214: 0.00\n",
      "aft_promo_260: 0.00\n",
      "aft_promo_2140: 0.00\n",
      "aft_promo_314: 0.00\n",
      "aft_promo_360: 0.00\n",
      "aft_promo_3140: 0.00\n",
      "aft_promo_414: 0.00\n",
      "aft_promo_460: 0.00\n",
      "aft_promo_4140: 0.00\n",
      "aft_promo_514: 0.00\n",
      "aft_promo_560: 0.00\n",
      "aft_promo_5140: 0.00\n",
      "promo_6: 0.00\n",
      "aft_promo_614: 0.00\n",
      "aft_promo_660: 0.00\n",
      "aft_promo_6140: 0.00\n",
      "mean_30_02: 0.00\n",
      "mean_60_02: 0.00\n",
      "mean_60_32: 0.00\n",
      "mean_14_51: 0.00\n",
      "mean_7_62: 0.00\n",
      "==================================================\n",
      "Step 5\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[33]\ttraining's rmse: 0.581833\tvalid_1's rmse: 0.604204\n",
      "mean_14_01: 545820.89\n",
      "mean_7_01: 458807.12\n",
      "mean_30_01: 358006.42\n",
      "mean_3_01: 217122.15\n",
      "promo_4: 69077.38\n",
      "mean_30_61: 35235.60\n",
      "mean_60_01: 29546.27\n",
      "mean_3_02: 11987.42\n",
      "promo_14days: 11442.76\n",
      "unpromo_14daysAfter: 7484.26\n",
      "mean_60_12: 7025.51\n",
      "family: 3836.61\n",
      "mean_3_51: 3672.05\n",
      "mean_30_62: 3325.16\n",
      "promo_0: 2938.96\n",
      "promo_60days: 2545.23\n",
      "mean_140_01: 2448.60\n",
      "type: 2179.98\n",
      "mean_30_52: 1904.87\n",
      "class: 1582.89\n",
      "mean_140_12: 1476.19\n",
      "mean_140_32: 1373.76\n",
      "mean_60_11: 1367.63\n",
      "promo_3: 1276.89\n",
      "mean_60_02: 1163.03\n",
      "mean_60_61: 1093.49\n",
      "promo_2: 1066.58\n",
      "mean_30_51: 861.65\n",
      "mean_140_22: 857.69\n",
      "mean_30_42: 795.20\n",
      "mean_140_42: 689.72\n",
      "mean_7_21: 640.57\n",
      "mean_30_32: 501.89\n",
      "mean_140_52: 451.12\n",
      "mean_140_62: 413.62\n",
      "mean_14_32: 409.23\n",
      "mean_30_12: 368.29\n",
      "mean_7_41: 333.51\n",
      "promo_1: 306.57\n",
      "mean_7_51: 300.91\n",
      "mean_3_62: 289.41\n",
      "mean_60_41: 254.67\n",
      "state: 233.48\n",
      "mean_7_42: 228.61\n",
      "mean_3_31: 225.47\n",
      "mean_14_22: 224.41\n",
      "mean_7_61: 202.39\n",
      "mean_14_61: 200.73\n",
      "mean_140_41: 179.86\n",
      "mean_3_52: 166.54\n",
      "mean_3_11: 166.07\n",
      "mean_3_12: 159.14\n",
      "mean_30_11: 154.91\n",
      "mean_7_62: 154.17\n",
      "mean_60_62: 150.42\n",
      "mean_14_21: 143.87\n",
      "mean_7_02: 138.88\n",
      "mean_3_61: 129.20\n",
      "promo_140days: 128.66\n",
      "mean_60_32: 125.58\n",
      "mean_60_51: 120.80\n",
      "mean_60_22: 119.05\n",
      "mean_30_22: 118.18\n",
      "mean_14_12: 115.40\n",
      "mean_140_11: 105.64\n",
      "mean_140_02: 91.31\n",
      "mean_60_52: 79.85\n",
      "mean_7_32: 71.25\n",
      "promo_5: 59.23\n",
      "mean_14_11: 59.14\n",
      "mean_140_21: 52.91\n",
      "perishable: 48.62\n",
      "city: 47.78\n",
      "mean_7_22: 45.20\n",
      "mean_7_11: 44.56\n",
      "mean_60_21: 38.98\n",
      "mean_30_21: 38.14\n",
      "mean_14_41: 37.65\n",
      "mean_14_51: 27.55\n",
      "cluster: 24.84\n",
      "aft_promo_014: 0.00\n",
      "aft_promo_060: 0.00\n",
      "aft_promo_0140: 0.00\n",
      "aft_promo_114: 0.00\n",
      "aft_promo_160: 0.00\n",
      "aft_promo_1140: 0.00\n",
      "aft_promo_214: 0.00\n",
      "aft_promo_260: 0.00\n",
      "aft_promo_2140: 0.00\n",
      "aft_promo_314: 0.00\n",
      "aft_promo_360: 0.00\n",
      "aft_promo_3140: 0.00\n",
      "aft_promo_414: 0.00\n",
      "aft_promo_460: 0.00\n",
      "aft_promo_4140: 0.00\n",
      "aft_promo_514: 0.00\n",
      "aft_promo_560: 0.00\n",
      "aft_promo_5140: 0.00\n",
      "promo_6: 0.00\n",
      "aft_promo_614: 0.00\n",
      "aft_promo_660: 0.00\n",
      "aft_promo_6140: 0.00\n",
      "mean_14_02: 0.00\n",
      "mean_30_02: 0.00\n",
      "mean_7_12: 0.00\n",
      "mean_3_21: 0.00\n",
      "mean_3_22: 0.00\n",
      "mean_3_32: 0.00\n",
      "mean_7_31: 0.00\n",
      "mean_14_31: 0.00\n",
      "mean_30_31: 0.00\n",
      "mean_60_31: 0.00\n",
      "mean_140_31: 0.00\n",
      "mean_3_41: 0.00\n",
      "mean_3_42: 0.00\n",
      "mean_14_42: 0.00\n",
      "mean_30_41: 0.00\n",
      "mean_60_42: 0.00\n",
      "mean_7_52: 0.00\n",
      "mean_14_52: 0.00\n",
      "mean_140_51: 0.00\n",
      "mean_14_62: 0.00\n",
      "mean_140_61: 0.00\n",
      "==================================================\n",
      "Step 6\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\ttraining's rmse: 0.577117\tvalid_1's rmse: 0.635029\n",
      "Early stopping, best iteration is:\n",
      "[140]\ttraining's rmse: 0.574054\tvalid_1's rmse: 0.634172\n",
      "mean_14_01: 452803.77\n",
      "mean_30_01: 360029.94\n",
      "mean_7_01: 343241.54\n",
      "mean_3_01: 200968.81\n",
      "promo_5: 51505.38\n",
      "mean_60_01: 41537.88\n",
      "promo_14days: 10046.66\n",
      "unpromo_14daysAfter: 9715.53\n",
      "mean_30_61: 9700.02\n",
      "mean_60_12: 7544.49\n",
      "mean_140_01: 6162.16\n",
      "mean_3_02: 4787.88\n",
      "class: 4584.59\n",
      "mean_3_11: 3352.62\n",
      "promo_0: 3181.62\n",
      "promo_60days: 3113.10\n",
      "mean_60_02: 3034.20\n",
      "family: 3001.45\n",
      "mean_140_22: 2816.60\n",
      "mean_140_12: 2441.90\n",
      "mean_60_61: 2082.91\n",
      "promo_4: 1959.73\n",
      "mean_3_51: 1591.37\n",
      "promo_140days: 1477.90\n",
      "mean_60_11: 1457.41\n",
      "mean_3_12: 1288.56\n",
      "mean_30_52: 1133.62\n",
      "mean_3_62: 1054.42\n",
      "mean_140_32: 1028.46\n",
      "type: 1022.42\n",
      "mean_30_11: 992.75\n",
      "perishable: 926.66\n",
      "mean_3_61: 914.46\n",
      "promo_2: 871.17\n",
      "mean_30_62: 841.29\n",
      "mean_60_52: 794.70\n",
      "mean_7_41: 773.24\n",
      "city: 741.78\n",
      "mean_14_12: 732.66\n",
      "mean_3_22: 692.88\n",
      "mean_3_31: 682.31\n",
      "mean_3_21: 678.26\n",
      "mean_3_41: 668.88\n",
      "mean_30_42: 661.15\n",
      "mean_30_02: 616.86\n",
      "mean_3_32: 592.71\n",
      "mean_7_61: 558.70\n",
      "mean_140_21: 549.36\n",
      "mean_7_62: 531.33\n",
      "mean_30_12: 520.56\n",
      "mean_7_22: 506.95\n",
      "mean_3_52: 471.21\n",
      "mean_7_12: 466.03\n",
      "mean_60_22: 462.99\n",
      "mean_14_22: 448.16\n",
      "promo_6: 444.65\n",
      "mean_7_21: 440.38\n",
      "mean_140_02: 440.09\n",
      "mean_3_42: 432.99\n",
      "mean_7_31: 426.48\n",
      "mean_140_42: 422.85\n",
      "cluster: 414.25\n",
      "mean_30_22: 413.43\n",
      "state: 385.45\n",
      "mean_140_11: 371.62\n",
      "mean_60_32: 369.39\n",
      "mean_7_11: 363.90\n",
      "mean_14_21: 348.25\n",
      "mean_7_02: 335.51\n",
      "mean_14_31: 323.62\n",
      "mean_60_62: 319.62\n",
      "mean_14_11: 312.62\n",
      "mean_7_51: 303.76\n",
      "mean_7_52: 294.26\n",
      "mean_30_41: 267.41\n",
      "promo_1: 261.67\n",
      "mean_60_42: 254.49\n",
      "mean_7_42: 250.38\n",
      "mean_140_51: 239.36\n",
      "mean_14_52: 235.98\n",
      "mean_14_61: 232.05\n",
      "mean_30_32: 218.35\n",
      "mean_7_32: 218.21\n",
      "mean_14_02: 201.25\n",
      "mean_14_41: 194.55\n",
      "mean_30_21: 190.57\n",
      "mean_60_21: 186.87\n",
      "mean_14_32: 180.38\n",
      "mean_30_51: 173.28\n",
      "mean_140_52: 145.70\n",
      "mean_60_31: 133.45\n",
      "mean_14_42: 130.66\n",
      "mean_14_51: 127.00\n",
      "mean_140_31: 124.27\n",
      "mean_140_61: 118.92\n",
      "mean_60_51: 109.93\n",
      "promo_3: 104.40\n",
      "mean_140_41: 98.99\n",
      "mean_30_31: 98.58\n",
      "mean_60_41: 92.93\n",
      "mean_14_62: 83.36\n",
      "mean_140_62: 48.68\n",
      "aft_promo_014: 0.00\n",
      "aft_promo_060: 0.00\n",
      "aft_promo_0140: 0.00\n",
      "aft_promo_114: 0.00\n",
      "aft_promo_160: 0.00\n",
      "aft_promo_1140: 0.00\n",
      "aft_promo_214: 0.00\n",
      "aft_promo_260: 0.00\n",
      "aft_promo_2140: 0.00\n",
      "aft_promo_314: 0.00\n",
      "aft_promo_360: 0.00\n",
      "aft_promo_3140: 0.00\n",
      "aft_promo_414: 0.00\n",
      "aft_promo_460: 0.00\n",
      "aft_promo_4140: 0.00\n",
      "aft_promo_514: 0.00\n",
      "aft_promo_560: 0.00\n",
      "aft_promo_5140: 0.00\n",
      "aft_promo_614: 0.00\n",
      "aft_promo_660: 0.00\n",
      "aft_promo_6140: 0.00\n",
      "==================================================\n",
      "Step 7\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[41]\ttraining's rmse: 0.592029\tvalid_1's rmse: 0.647411\n",
      "mean_30_01: 701071.11\n",
      "mean_14_01: 345833.36\n",
      "mean_3_01: 305638.36\n",
      "mean_7_01: 152159.22\n",
      "promo_6: 63835.91\n",
      "mean_60_01: 38740.97\n",
      "mean_3_11: 25397.47\n",
      "mean_30_61: 20690.02\n",
      "promo_14days: 9858.58\n",
      "unpromo_14daysAfter: 8726.13\n",
      "mean_60_12: 7484.73\n",
      "mean_60_21: 6846.90\n",
      "mean_3_02: 5681.60\n",
      "mean_3_12: 4829.17\n",
      "mean_140_01: 4499.36\n",
      "promo_60days: 4495.44\n",
      "class: 4370.44\n",
      "mean_140_12: 3797.47\n",
      "family: 3383.87\n",
      "mean_30_02: 3167.63\n",
      "mean_140_22: 2206.65\n",
      "mean_60_11: 1597.32\n",
      "promo_140days: 1449.88\n",
      "type: 1385.69\n",
      "promo_4: 1179.15\n",
      "mean_3_21: 1089.68\n",
      "mean_140_21: 912.27\n",
      "mean_60_22: 912.00\n",
      "promo_1: 870.64\n",
      "mean_3_61: 861.68\n",
      "promo_2: 709.72\n",
      "mean_3_51: 689.78\n",
      "mean_30_11: 639.54\n",
      "promo_0: 599.56\n",
      "promo_5: 594.73\n",
      "perishable: 571.53\n",
      "mean_60_02: 483.07\n",
      "mean_14_12: 420.56\n",
      "mean_7_02: 397.26\n",
      "cluster: 393.78\n",
      "mean_140_41: 359.02\n",
      "mean_140_11: 348.51\n",
      "mean_3_62: 345.39\n",
      "mean_3_31: 338.07\n",
      "mean_3_32: 321.00\n",
      "mean_30_22: 310.59\n",
      "mean_30_12: 263.20\n",
      "city: 257.42\n",
      "mean_30_32: 241.63\n",
      "mean_7_11: 199.51\n",
      "mean_7_31: 195.72\n",
      "mean_60_62: 186.32\n",
      "mean_60_32: 172.43\n",
      "mean_140_32: 169.01\n",
      "mean_140_31: 163.03\n",
      "mean_3_42: 157.34\n",
      "state: 133.34\n",
      "mean_30_52: 122.13\n",
      "mean_60_42: 118.95\n",
      "mean_3_22: 112.17\n",
      "mean_7_21: 109.45\n",
      "mean_140_02: 109.20\n",
      "mean_14_21: 107.92\n",
      "mean_14_22: 107.51\n",
      "mean_30_31: 105.28\n",
      "mean_3_41: 100.49\n",
      "mean_7_41: 97.66\n",
      "mean_60_61: 89.88\n",
      "mean_140_52: 89.19\n",
      "mean_3_52: 88.10\n",
      "mean_7_22: 82.31\n",
      "mean_14_41: 79.22\n",
      "mean_30_42: 77.06\n",
      "mean_14_51: 73.45\n",
      "mean_7_32: 68.94\n",
      "mean_140_42: 57.32\n",
      "mean_14_61: 53.23\n",
      "mean_7_62: 32.66\n",
      "mean_140_61: 29.86\n",
      "mean_14_62: 29.16\n",
      "aft_promo_014: 0.00\n",
      "aft_promo_060: 0.00\n",
      "aft_promo_0140: 0.00\n",
      "aft_promo_114: 0.00\n",
      "aft_promo_160: 0.00\n",
      "aft_promo_1140: 0.00\n",
      "aft_promo_214: 0.00\n",
      "aft_promo_260: 0.00\n",
      "aft_promo_2140: 0.00\n",
      "promo_3: 0.00\n",
      "aft_promo_314: 0.00\n",
      "aft_promo_360: 0.00\n",
      "aft_promo_3140: 0.00\n",
      "aft_promo_414: 0.00\n",
      "aft_promo_460: 0.00\n",
      "aft_promo_4140: 0.00\n",
      "aft_promo_514: 0.00\n",
      "aft_promo_560: 0.00\n",
      "aft_promo_5140: 0.00\n",
      "aft_promo_614: 0.00\n",
      "aft_promo_660: 0.00\n",
      "aft_promo_6140: 0.00\n",
      "mean_14_02: 0.00\n",
      "mean_7_12: 0.00\n",
      "mean_14_11: 0.00\n",
      "mean_30_21: 0.00\n",
      "mean_14_31: 0.00\n",
      "mean_14_32: 0.00\n",
      "mean_60_31: 0.00\n",
      "mean_7_42: 0.00\n",
      "mean_14_42: 0.00\n",
      "mean_30_41: 0.00\n",
      "mean_60_41: 0.00\n",
      "mean_7_51: 0.00\n",
      "mean_7_52: 0.00\n",
      "mean_14_52: 0.00\n",
      "mean_30_51: 0.00\n",
      "mean_60_51: 0.00\n",
      "mean_60_52: 0.00\n",
      "mean_140_51: 0.00\n",
      "mean_7_61: 0.00\n",
      "mean_30_62: 0.00\n",
      "mean_140_62: 0.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Step 8\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[42]\ttraining's rmse: 0.61145\tvalid_1's rmse: 0.626622\n",
      "mean_30_01: 699228.48\n",
      "mean_7_01: 491181.59\n",
      "mean_14_01: 466677.22\n",
      "mean_3_01: 39456.90\n",
      "unpromo_14daysAfter: 37744.29\n",
      "mean_60_01: 36741.81\n",
      "mean_3_21: 20282.27\n",
      "mean_60_21: 11370.21\n",
      "mean_60_31: 10327.89\n",
      "promo_14days: 10314.47\n",
      "mean_140_01: 8104.57\n",
      "mean_3_22: 7496.57\n",
      "mean_60_22: 4970.09\n",
      "mean_140_12: 4062.79\n",
      "mean_140_22: 3168.49\n",
      "type: 2972.30\n",
      "promo_60days: 2782.33\n",
      "mean_30_21: 2346.86\n",
      "mean_60_12: 2280.28\n",
      "mean_3_31: 2143.50\n",
      "mean_140_61: 1886.40\n",
      "class: 1866.63\n",
      "family: 1607.73\n",
      "city: 1386.02\n",
      "mean_60_11: 1348.10\n",
      "promo_6: 1327.04\n",
      "mean_60_61: 1267.65\n",
      "mean_30_12: 1157.62\n",
      "mean_3_41: 1064.73\n",
      "perishable: 992.07\n",
      "cluster: 968.21\n",
      "mean_30_61: 894.24\n",
      "mean_3_11: 848.11\n",
      "mean_140_21: 845.41\n",
      "mean_140_32: 750.60\n",
      "promo_140days: 672.87\n",
      "promo_2: 628.01\n",
      "state: 596.68\n",
      "mean_60_32: 457.48\n",
      "mean_3_51: 456.97\n",
      "promo_1: 449.18\n",
      "mean_3_12: 439.01\n",
      "mean_7_02: 433.01\n",
      "mean_14_12: 430.82\n",
      "mean_30_11: 401.39\n",
      "mean_30_22: 396.91\n",
      "mean_140_42: 308.66\n",
      "promo_4: 283.93\n",
      "mean_140_11: 271.70\n",
      "mean_14_41: 189.39\n",
      "mean_7_21: 170.13\n",
      "mean_14_62: 159.45\n",
      "mean_140_52: 156.84\n",
      "mean_30_02: 155.72\n",
      "mean_7_31: 154.45\n",
      "mean_140_02: 152.75\n",
      "mean_60_62: 141.34\n",
      "mean_14_31: 131.10\n",
      "mean_14_22: 113.58\n",
      "mean_30_62: 112.39\n",
      "mean_14_11: 106.69\n",
      "mean_3_52: 106.50\n",
      "mean_7_12: 100.89\n",
      "mean_30_32: 98.55\n",
      "mean_14_61: 90.28\n",
      "mean_14_21: 83.24\n",
      "mean_3_61: 83.07\n",
      "mean_3_42: 80.18\n",
      "mean_3_32: 79.19\n",
      "mean_14_51: 73.05\n",
      "mean_7_11: 69.42\n",
      "mean_3_02: 68.41\n",
      "mean_14_52: 66.21\n",
      "mean_30_51: 61.71\n",
      "mean_3_62: 60.64\n",
      "mean_140_31: 60.08\n",
      "mean_60_41: 50.13\n",
      "mean_60_42: 44.50\n",
      "promo_5: 44.25\n",
      "promo_3: 39.80\n",
      "mean_7_51: 35.07\n",
      "mean_140_41: 32.10\n",
      "mean_14_32: 30.90\n",
      "mean_140_62: 29.93\n",
      "mean_7_61: 29.14\n",
      "mean_7_22: 28.71\n",
      "mean_140_51: 27.31\n",
      "mean_7_32: 20.25\n",
      "promo_0: 0.00\n",
      "aft_promo_014: 0.00\n",
      "aft_promo_060: 0.00\n",
      "aft_promo_0140: 0.00\n",
      "aft_promo_114: 0.00\n",
      "aft_promo_160: 0.00\n",
      "aft_promo_1140: 0.00\n",
      "aft_promo_214: 0.00\n",
      "aft_promo_260: 0.00\n",
      "aft_promo_2140: 0.00\n",
      "aft_promo_314: 0.00\n",
      "aft_promo_360: 0.00\n",
      "aft_promo_3140: 0.00\n",
      "aft_promo_414: 0.00\n",
      "aft_promo_460: 0.00\n",
      "aft_promo_4140: 0.00\n",
      "aft_promo_514: 0.00\n",
      "aft_promo_560: 0.00\n",
      "aft_promo_5140: 0.00\n",
      "aft_promo_614: 0.00\n",
      "aft_promo_660: 0.00\n",
      "aft_promo_6140: 0.00\n",
      "mean_14_02: 0.00\n",
      "mean_60_02: 0.00\n",
      "mean_30_31: 0.00\n",
      "mean_7_41: 0.00\n",
      "mean_7_42: 0.00\n",
      "mean_14_42: 0.00\n",
      "mean_30_41: 0.00\n",
      "mean_30_42: 0.00\n",
      "mean_7_52: 0.00\n",
      "mean_30_52: 0.00\n",
      "mean_60_51: 0.00\n",
      "mean_60_52: 0.00\n",
      "mean_7_62: 0.00\n",
      "==================================================\n",
      "Step 9\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\ttraining's rmse: 0.609608\tvalid_1's rmse: 0.644694\n",
      "[200]\ttraining's rmse: 0.599532\tvalid_1's rmse: 0.641345\n",
      "[300]\ttraining's rmse: 0.592597\tvalid_1's rmse: 0.639797\n",
      "[400]\ttraining's rmse: 0.586544\tvalid_1's rmse: 0.639002\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[400]\ttraining's rmse: 0.586544\tvalid_1's rmse: 0.639002\n",
      "mean_14_01: 758682.25\n",
      "mean_30_01: 493278.88\n",
      "mean_7_01: 377095.95\n",
      "mean_3_31: 57395.30\n",
      "mean_60_01: 57349.05\n",
      "mean_30_61: 50583.01\n",
      "unpromo_14daysAfter: 47601.33\n",
      "mean_60_41: 36189.30\n",
      "mean_30_21: 25050.47\n",
      "mean_3_32: 20645.67\n",
      "class: 13610.52\n",
      "promo_14days: 13380.49\n",
      "mean_3_01: 12955.37\n",
      "mean_140_01: 11524.76\n",
      "type: 9249.35\n",
      "mean_60_51: 8547.10\n",
      "city: 7754.67\n",
      "state: 6506.09\n",
      "cluster: 6429.54\n",
      "mean_3_41: 5967.81\n",
      "family: 5166.69\n",
      "mean_140_12: 4835.89\n",
      "mean_140_22: 4641.91\n",
      "mean_140_61: 4397.23\n",
      "promo_60days: 4370.34\n",
      "mean_60_32: 4125.51\n",
      "mean_60_31: 3749.09\n",
      "mean_3_51: 3226.99\n",
      "promo_140days: 2889.51\n",
      "mean_3_22: 2840.61\n",
      "mean_3_12: 2768.97\n",
      "mean_60_12: 2743.41\n",
      "mean_60_42: 2710.60\n",
      "mean_3_52: 2375.37\n",
      "mean_3_11: 2327.96\n",
      "mean_3_61: 2187.36\n",
      "mean_3_21: 2162.95\n",
      "mean_3_42: 2146.79\n",
      "mean_140_32: 2144.20\n",
      "mean_7_12: 2051.12\n",
      "mean_3_02: 1928.82\n",
      "mean_14_12: 1928.33\n",
      "promo_1: 1765.02\n",
      "mean_30_22: 1654.01\n",
      "mean_60_22: 1628.71\n",
      "mean_140_41: 1466.00\n",
      "mean_3_62: 1408.05\n",
      "mean_30_12: 1352.11\n",
      "mean_7_32: 1255.09\n",
      "mean_7_21: 1220.62\n",
      "perishable: 1125.50\n",
      "mean_7_41: 1073.86\n",
      "mean_7_31: 1036.86\n",
      "mean_30_11: 1023.26\n",
      "mean_7_02: 985.85\n",
      "mean_7_61: 985.73\n",
      "mean_7_42: 954.11\n",
      "mean_14_02: 947.42\n",
      "mean_7_22: 932.48\n",
      "mean_7_52: 911.45\n",
      "mean_14_41: 889.31\n",
      "promo_6: 854.12\n",
      "mean_7_11: 853.87\n",
      "mean_7_51: 842.47\n",
      "promo_4: 840.43\n",
      "mean_140_51: 829.30\n",
      "mean_14_32: 817.32\n",
      "mean_14_42: 813.44\n",
      "mean_14_61: 804.08\n",
      "mean_140_42: 802.72\n",
      "mean_30_32: 774.08\n",
      "mean_14_22: 764.12\n",
      "mean_7_62: 754.30\n",
      "mean_140_21: 748.79\n",
      "mean_30_62: 683.65\n",
      "mean_14_21: 678.37\n",
      "mean_14_62: 668.15\n",
      "mean_14_31: 659.49\n",
      "mean_60_21: 658.27\n",
      "mean_140_31: 656.14\n",
      "mean_30_42: 652.68\n",
      "promo_2: 651.67\n",
      "mean_14_52: 620.55\n",
      "mean_140_62: 606.52\n",
      "mean_30_41: 605.23\n",
      "mean_60_11: 572.52\n",
      "mean_140_52: 545.00\n",
      "mean_14_51: 544.17\n",
      "promo_3: 522.86\n",
      "mean_140_02: 517.14\n",
      "mean_30_31: 483.56\n",
      "mean_14_11: 459.85\n",
      "mean_30_02: 434.59\n",
      "mean_60_61: 411.72\n",
      "mean_60_52: 408.72\n",
      "mean_60_02: 400.64\n",
      "mean_30_51: 399.62\n",
      "mean_30_52: 349.19\n",
      "mean_60_62: 316.50\n",
      "promo_5: 292.33\n",
      "mean_140_11: 267.03\n",
      "promo_0: 211.74\n",
      "aft_promo_014: 0.00\n",
      "aft_promo_060: 0.00\n",
      "aft_promo_0140: 0.00\n",
      "aft_promo_114: 0.00\n",
      "aft_promo_160: 0.00\n",
      "aft_promo_1140: 0.00\n",
      "aft_promo_214: 0.00\n",
      "aft_promo_260: 0.00\n",
      "aft_promo_2140: 0.00\n",
      "aft_promo_314: 0.00\n",
      "aft_promo_360: 0.00\n",
      "aft_promo_3140: 0.00\n",
      "aft_promo_414: 0.00\n",
      "aft_promo_460: 0.00\n",
      "aft_promo_4140: 0.00\n",
      "aft_promo_514: 0.00\n",
      "aft_promo_560: 0.00\n",
      "aft_promo_5140: 0.00\n",
      "aft_promo_614: 0.00\n",
      "aft_promo_660: 0.00\n",
      "aft_promo_6140: 0.00\n",
      "==================================================\n",
      "Step 10\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\ttraining's rmse: 0.605706\tvalid_1's rmse: 0.607868\n",
      "[200]\ttraining's rmse: 0.597501\tvalid_1's rmse: 0.605366\n",
      "[300]\ttraining's rmse: 0.591315\tvalid_1's rmse: 0.604599\n",
      "[400]\ttraining's rmse: 0.586151\tvalid_1's rmse: 0.604073\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[400]\ttraining's rmse: 0.586151\tvalid_1's rmse: 0.604073\n",
      "mean_30_01: 589019.64\n",
      "mean_7_01: 451251.61\n",
      "mean_14_01: 419704.81\n",
      "mean_60_01: 58995.05\n",
      "unpromo_14daysAfter: 41648.15\n",
      "mean_3_01: 18040.98\n",
      "mean_30_61: 16623.44\n",
      "mean_30_41: 14603.41\n",
      "mean_60_51: 13341.77\n",
      "mean_3_41: 12685.66\n",
      "class: 12009.39\n",
      "promo_14days: 11134.01\n",
      "mean_140_01: 7614.57\n",
      "mean_60_61: 6400.18\n",
      "mean_30_31: 5439.61\n",
      "family: 5131.05\n",
      "promo_60days: 5126.86\n",
      "mean_7_12: 3946.10\n",
      "mean_3_42: 3782.71\n",
      "mean_3_51: 3602.32\n",
      "mean_60_41: 3077.76\n",
      "mean_60_42: 3018.01\n",
      "promo_140days: 2806.00\n",
      "mean_140_31: 2507.54\n",
      "mean_140_32: 2487.15\n",
      "mean_3_61: 2469.86\n",
      "mean_3_12: 2296.11\n",
      "mean_3_11: 2080.53\n",
      "mean_140_22: 2028.71\n",
      "mean_140_12: 2003.16\n",
      "mean_140_42: 1999.95\n",
      "mean_140_62: 1864.92\n",
      "mean_3_62: 1859.32\n",
      "mean_140_61: 1858.30\n",
      "mean_30_32: 1844.61\n",
      "mean_60_12: 1789.05\n",
      "mean_3_22: 1749.18\n",
      "mean_3_31: 1717.91\n",
      "cluster: 1704.87\n",
      "mean_60_62: 1645.59\n",
      "mean_3_21: 1582.72\n",
      "mean_60_52: 1562.54\n",
      "mean_3_02: 1559.02\n",
      "city: 1522.99\n",
      "mean_3_32: 1488.69\n",
      "mean_3_52: 1383.62\n",
      "mean_7_51: 1298.50\n",
      "type: 1282.73\n",
      "mean_14_62: 1234.00\n",
      "mean_7_41: 1187.67\n",
      "mean_14_12: 1174.16\n",
      "promo_4: 1123.45\n",
      "mean_140_02: 1091.43\n",
      "mean_30_12: 1087.11\n",
      "state: 1086.38\n",
      "mean_7_32: 1005.74\n",
      "mean_7_22: 989.06\n",
      "mean_7_61: 967.97\n",
      "mean_7_31: 883.07\n",
      "mean_14_02: 862.12\n",
      "mean_140_11: 848.78\n",
      "mean_7_52: 845.83\n",
      "mean_30_42: 839.58\n",
      "mean_30_11: 835.50\n",
      "perishable: 831.17\n",
      "mean_140_52: 827.02\n",
      "promo_2: 821.53\n",
      "mean_14_42: 806.65\n",
      "mean_7_02: 800.16\n",
      "mean_7_21: 787.70\n",
      "mean_7_11: 779.96\n",
      "mean_14_31: 770.99\n",
      "mean_7_62: 761.90\n",
      "mean_14_61: 750.34\n",
      "mean_14_41: 739.41\n",
      "mean_30_21: 732.10\n",
      "mean_140_41: 724.43\n",
      "mean_60_32: 718.52\n",
      "mean_30_22: 715.50\n",
      "mean_60_22: 700.92\n",
      "mean_14_52: 687.95\n",
      "mean_14_32: 686.24\n",
      "promo_0: 683.18\n",
      "mean_140_21: 648.07\n",
      "mean_60_11: 642.53\n",
      "mean_7_42: 639.98\n",
      "mean_30_51: 591.94\n",
      "mean_14_22: 584.42\n",
      "promo_3: 577.92\n",
      "mean_14_21: 515.27\n",
      "promo_1: 509.73\n",
      "promo_6: 501.96\n",
      "promo_5: 493.59\n",
      "mean_14_11: 482.10\n",
      "mean_60_02: 456.75\n",
      "mean_14_51: 456.21\n",
      "mean_30_62: 423.97\n",
      "mean_30_52: 418.83\n",
      "mean_30_02: 413.16\n",
      "mean_60_31: 408.92\n",
      "mean_60_21: 385.11\n",
      "mean_140_51: 321.58\n",
      "aft_promo_014: 0.00\n",
      "aft_promo_060: 0.00\n",
      "aft_promo_0140: 0.00\n",
      "aft_promo_114: 0.00\n",
      "aft_promo_160: 0.00\n",
      "aft_promo_1140: 0.00\n",
      "aft_promo_214: 0.00\n",
      "aft_promo_260: 0.00\n",
      "aft_promo_2140: 0.00\n",
      "aft_promo_314: 0.00\n",
      "aft_promo_360: 0.00\n",
      "aft_promo_3140: 0.00\n",
      "aft_promo_414: 0.00\n",
      "aft_promo_460: 0.00\n",
      "aft_promo_4140: 0.00\n",
      "aft_promo_514: 0.00\n",
      "aft_promo_560: 0.00\n",
      "aft_promo_5140: 0.00\n",
      "aft_promo_614: 0.00\n",
      "aft_promo_660: 0.00\n",
      "aft_promo_6140: 0.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Step 11\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\ttraining's rmse: 0.608226\tvalid_1's rmse: 0.62683\n",
      "[200]\ttraining's rmse: 0.599384\tvalid_1's rmse: 0.62534\n",
      "[300]\ttraining's rmse: 0.592885\tvalid_1's rmse: 0.624948\n",
      "[400]\ttraining's rmse: 0.587374\tvalid_1's rmse: 0.624461\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[400]\ttraining's rmse: 0.587374\tvalid_1's rmse: 0.624461\n",
      "mean_30_01: 562665.86\n",
      "mean_7_01: 405200.61\n",
      "mean_14_01: 384909.06\n",
      "unpromo_14daysAfter: 48079.98\n",
      "mean_30_61: 47383.02\n",
      "mean_60_01: 34389.26\n",
      "mean_60_61: 31842.76\n",
      "mean_3_61: 26516.80\n",
      "mean_3_01: 15480.92\n",
      "mean_7_12: 15083.29\n",
      "promo_14days: 12209.70\n",
      "class: 11544.45\n",
      "family: 10058.42\n",
      "mean_140_01: 8319.19\n",
      "mean_3_41: 8128.88\n",
      "promo_3: 8080.55\n",
      "mean_60_51: 6636.21\n",
      "type: 6394.86\n",
      "mean_14_52: 5221.85\n",
      "mean_30_41: 5200.24\n",
      "promo_60days: 5154.54\n",
      "mean_140_12: 4701.66\n",
      "mean_14_02: 3143.05\n",
      "mean_140_32: 3018.34\n",
      "mean_30_51: 2845.23\n",
      "promo_4: 2749.30\n",
      "promo_140days: 2727.68\n",
      "mean_3_51: 2679.67\n",
      "mean_3_22: 2317.71\n",
      "mean_140_42: 2285.82\n",
      "mean_140_21: 2117.41\n",
      "mean_3_31: 2037.62\n",
      "city: 1945.31\n",
      "mean_60_62: 1938.95\n",
      "mean_140_22: 1911.70\n",
      "mean_3_12: 1899.83\n",
      "mean_3_11: 1836.45\n",
      "mean_60_41: 1811.44\n",
      "mean_140_51: 1790.26\n",
      "mean_3_32: 1776.64\n",
      "mean_14_12: 1769.60\n",
      "mean_3_42: 1740.23\n",
      "mean_60_12: 1693.75\n",
      "mean_140_61: 1661.78\n",
      "mean_3_52: 1644.02\n",
      "mean_3_21: 1641.96\n",
      "mean_3_62: 1611.46\n",
      "mean_3_02: 1431.05\n",
      "mean_14_62: 1370.26\n",
      "perishable: 1369.42\n",
      "mean_140_02: 1215.95\n",
      "mean_30_12: 1191.98\n",
      "mean_140_41: 1179.68\n",
      "mean_140_31: 1140.73\n",
      "mean_7_31: 1113.55\n",
      "mean_30_11: 1057.29\n",
      "mean_7_41: 1046.27\n",
      "mean_7_22: 1012.80\n",
      "state: 985.96\n",
      "mean_7_51: 982.84\n",
      "mean_7_11: 972.24\n",
      "mean_7_61: 958.70\n",
      "mean_60_52: 957.01\n",
      "mean_7_62: 918.54\n",
      "mean_7_21: 897.33\n",
      "mean_7_42: 895.94\n",
      "mean_140_11: 890.08\n",
      "mean_60_02: 880.52\n",
      "promo_0: 859.67\n",
      "mean_14_32: 833.46\n",
      "cluster: 829.37\n",
      "mean_7_32: 821.34\n",
      "mean_30_32: 768.02\n",
      "mean_14_22: 736.80\n",
      "mean_7_52: 727.22\n",
      "mean_14_51: 696.04\n",
      "promo_1: 695.39\n",
      "mean_140_62: 685.87\n",
      "mean_14_31: 683.22\n",
      "mean_14_42: 666.75\n",
      "promo_5: 661.21\n",
      "promo_2: 652.22\n",
      "mean_60_22: 641.22\n",
      "promo_6: 621.87\n",
      "mean_14_21: 617.43\n",
      "mean_7_02: 616.49\n",
      "mean_14_61: 578.21\n",
      "mean_30_22: 553.50\n",
      "mean_30_42: 551.37\n",
      "mean_14_11: 529.10\n",
      "mean_14_41: 515.41\n",
      "mean_30_31: 508.65\n",
      "mean_140_52: 502.57\n",
      "mean_30_02: 495.68\n",
      "mean_60_32: 495.21\n",
      "mean_30_52: 477.31\n",
      "mean_30_21: 433.43\n",
      "mean_30_62: 433.02\n",
      "mean_60_11: 412.58\n",
      "mean_60_21: 396.14\n",
      "mean_60_31: 370.01\n",
      "mean_60_42: 359.18\n",
      "aft_promo_014: 0.00\n",
      "aft_promo_060: 0.00\n",
      "aft_promo_0140: 0.00\n",
      "aft_promo_114: 0.00\n",
      "aft_promo_160: 0.00\n",
      "aft_promo_1140: 0.00\n",
      "aft_promo_214: 0.00\n",
      "aft_promo_260: 0.00\n",
      "aft_promo_2140: 0.00\n",
      "aft_promo_314: 0.00\n",
      "aft_promo_360: 0.00\n",
      "aft_promo_3140: 0.00\n",
      "aft_promo_414: 0.00\n",
      "aft_promo_460: 0.00\n",
      "aft_promo_4140: 0.00\n",
      "aft_promo_514: 0.00\n",
      "aft_promo_560: 0.00\n",
      "aft_promo_5140: 0.00\n",
      "aft_promo_614: 0.00\n",
      "aft_promo_660: 0.00\n",
      "aft_promo_6140: 0.00\n",
      "==================================================\n",
      "Step 12\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\ttraining's rmse: 0.595327\tvalid_1's rmse: 0.622738\n",
      "[200]\ttraining's rmse: 0.586558\tvalid_1's rmse: 0.620856\n",
      "[300]\ttraining's rmse: 0.58022\tvalid_1's rmse: 0.619589\n",
      "[400]\ttraining's rmse: 0.574784\tvalid_1's rmse: 0.619612\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[400]\ttraining's rmse: 0.574784\tvalid_1's rmse: 0.619612\n",
      "mean_30_01: 658703.83\n",
      "mean_30_61: 294320.55\n",
      "mean_7_01: 234977.65\n",
      "mean_3_01: 142582.76\n",
      "mean_14_01: 138613.85\n",
      "mean_60_01: 76496.66\n",
      "unpromo_14daysAfter: 55849.66\n",
      "mean_7_12: 13452.30\n",
      "promo_14days: 12651.28\n",
      "promo_4: 12277.88\n",
      "class: 11663.66\n",
      "family: 8231.02\n",
      "mean_3_02: 6933.72\n",
      "mean_140_01: 6711.08\n",
      "mean_14_02: 6573.93\n",
      "mean_60_12: 5950.73\n",
      "mean_60_02: 5825.29\n",
      "mean_14_12: 5451.55\n",
      "promo_60days: 5334.94\n",
      "perishable: 5315.65\n",
      "mean_3_51: 4691.23\n",
      "mean_60_62: 4541.10\n",
      "type: 3865.01\n",
      "promo_140days: 3203.03\n",
      "mean_140_41: 3064.30\n",
      "mean_140_22: 2993.07\n",
      "promo_3: 2894.64\n",
      "mean_3_61: 2682.32\n",
      "mean_60_22: 2197.05\n",
      "mean_140_12: 2187.79\n",
      "city: 2155.53\n",
      "cluster: 1849.13\n",
      "mean_3_22: 1836.35\n",
      "mean_3_32: 1733.67\n",
      "mean_60_61: 1688.66\n",
      "promo_1: 1677.75\n",
      "mean_140_31: 1647.34\n",
      "mean_3_52: 1623.77\n",
      "mean_3_12: 1606.77\n",
      "mean_3_11: 1564.31\n",
      "mean_60_21: 1562.44\n",
      "mean_3_41: 1520.39\n",
      "state: 1491.24\n",
      "mean_3_31: 1427.61\n",
      "mean_30_12: 1334.62\n",
      "mean_3_42: 1295.02\n",
      "mean_3_62: 1272.43\n",
      "mean_30_51: 1178.92\n",
      "mean_30_22: 1170.80\n",
      "mean_7_51: 1161.49\n",
      "mean_7_61: 1147.99\n",
      "mean_7_32: 1138.98\n",
      "mean_3_21: 1137.42\n",
      "mean_30_41: 1095.11\n",
      "mean_7_22: 1063.58\n",
      "mean_7_41: 1015.70\n",
      "mean_30_62: 982.71\n",
      "mean_14_22: 966.72\n",
      "mean_7_31: 947.46\n",
      "mean_7_62: 944.15\n",
      "mean_140_51: 922.92\n",
      "mean_140_42: 915.77\n",
      "promo_2: 913.90\n",
      "mean_7_21: 877.92\n",
      "mean_14_11: 860.24\n",
      "mean_7_42: 846.83\n",
      "mean_7_11: 825.67\n",
      "mean_140_21: 781.87\n",
      "mean_140_11: 777.48\n",
      "mean_60_32: 762.52\n",
      "promo_6: 757.54\n",
      "mean_14_32: 752.09\n",
      "mean_14_52: 735.25\n",
      "promo_5: 716.59\n",
      "mean_30_42: 710.04\n",
      "mean_140_52: 685.12\n",
      "mean_14_61: 667.21\n",
      "mean_14_42: 657.50\n",
      "mean_7_52: 646.51\n",
      "mean_7_02: 646.45\n",
      "mean_30_31: 641.29\n",
      "mean_14_31: 636.29\n",
      "mean_14_41: 633.56\n",
      "mean_14_51: 618.65\n",
      "mean_60_41: 613.62\n",
      "mean_14_62: 603.09\n",
      "mean_30_32: 597.97\n",
      "mean_140_62: 592.29\n",
      "mean_14_21: 535.88\n",
      "mean_140_61: 533.61\n",
      "promo_0: 532.23\n",
      "mean_60_11: 526.38\n",
      "mean_60_42: 520.47\n",
      "mean_140_32: 511.28\n",
      "mean_30_21: 504.04\n",
      "mean_60_52: 476.33\n",
      "mean_140_02: 468.95\n",
      "mean_60_51: 411.87\n",
      "mean_30_52: 399.77\n",
      "mean_30_11: 387.87\n",
      "mean_30_02: 371.48\n",
      "mean_60_31: 226.39\n",
      "aft_promo_014: 0.00\n",
      "aft_promo_060: 0.00\n",
      "aft_promo_0140: 0.00\n",
      "aft_promo_114: 0.00\n",
      "aft_promo_160: 0.00\n",
      "aft_promo_1140: 0.00\n",
      "aft_promo_214: 0.00\n",
      "aft_promo_260: 0.00\n",
      "aft_promo_2140: 0.00\n",
      "aft_promo_314: 0.00\n",
      "aft_promo_360: 0.00\n",
      "aft_promo_3140: 0.00\n",
      "aft_promo_414: 0.00\n",
      "aft_promo_460: 0.00\n",
      "aft_promo_4140: 0.00\n",
      "aft_promo_514: 0.00\n",
      "aft_promo_560: 0.00\n",
      "aft_promo_5140: 0.00\n",
      "aft_promo_614: 0.00\n",
      "aft_promo_660: 0.00\n",
      "aft_promo_6140: 0.00\n",
      "==================================================\n",
      "Step 13\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\ttraining's rmse: 0.603954\tvalid_1's rmse: 0.615591\n",
      "[200]\ttraining's rmse: 0.595342\tvalid_1's rmse: 0.612417\n",
      "[300]\ttraining's rmse: 0.588888\tvalid_1's rmse: 0.611403\n",
      "[400]\ttraining's rmse: 0.583349\tvalid_1's rmse: 0.610894\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[400]\ttraining's rmse: 0.583349\tvalid_1's rmse: 0.610894\n",
      "mean_30_01: 677082.69\n",
      "mean_30_61: 244184.10\n",
      "mean_14_01: 170926.60\n",
      "mean_7_01: 93102.50\n",
      "mean_3_01: 77998.70\n",
      "mean_60_01: 57041.13\n",
      "unpromo_14daysAfter: 35708.57\n",
      "promo_14days: 13464.94\n",
      "class: 12486.67\n",
      "mean_140_01: 7276.47\n",
      "mean_60_61: 7042.83\n",
      "mean_3_12: 6980.27\n",
      "promo_60days: 6467.17\n",
      "mean_3_11: 6381.40\n",
      "mean_7_12: 6211.74\n",
      "family: 4523.46\n",
      "promo_140days: 3953.47\n",
      "mean_140_62: 3539.30\n",
      "mean_60_12: 3525.68\n",
      "mean_3_02: 3230.53\n",
      "promo_4: 2640.83\n",
      "mean_140_12: 2624.21\n",
      "mean_60_62: 2612.48\n",
      "type: 2603.99\n",
      "mean_140_22: 2261.06\n",
      "mean_3_41: 2164.89\n",
      "mean_3_51: 2033.76\n",
      "mean_3_32: 1994.05\n",
      "mean_60_21: 1961.99\n",
      "mean_3_61: 1959.55\n",
      "mean_3_31: 1943.99\n",
      "promo_5: 1937.87\n",
      "mean_14_52: 1879.83\n",
      "mean_60_11: 1797.01\n",
      "mean_14_12: 1709.54\n",
      "mean_140_32: 1702.95\n",
      "city: 1628.80\n",
      "mean_3_22: 1544.19\n",
      "mean_3_42: 1535.35\n",
      "mean_3_62: 1528.47\n",
      "cluster: 1500.00\n",
      "mean_3_52: 1401.41\n",
      "mean_7_21: 1380.48\n",
      "promo_1: 1333.62\n",
      "mean_30_12: 1326.79\n",
      "mean_3_21: 1302.00\n",
      "promo_0: 1284.82\n",
      "promo_6: 1227.09\n",
      "promo_3: 1208.85\n",
      "mean_7_51: 1163.74\n",
      "mean_7_41: 1132.04\n",
      "mean_7_22: 1090.26\n",
      "state: 1080.17\n",
      "promo_2: 1066.15\n",
      "mean_60_02: 1052.32\n",
      "mean_7_31: 1003.43\n",
      "mean_7_61: 984.01\n",
      "mean_7_42: 980.96\n",
      "mean_140_21: 974.45\n",
      "mean_14_41: 955.58\n",
      "mean_7_32: 884.52\n",
      "mean_140_31: 881.11\n",
      "mean_140_42: 863.81\n",
      "mean_140_02: 829.43\n",
      "mean_30_42: 812.18\n",
      "mean_140_61: 792.38\n",
      "mean_30_31: 790.94\n",
      "mean_30_62: 785.28\n",
      "mean_30_22: 779.74\n",
      "mean_7_52: 760.18\n",
      "mean_14_51: 744.78\n",
      "mean_140_51: 733.87\n",
      "mean_14_02: 725.58\n",
      "perishable: 715.82\n",
      "mean_140_41: 685.09\n",
      "mean_7_11: 666.38\n",
      "mean_30_02: 660.98\n",
      "mean_14_22: 657.91\n",
      "mean_14_31: 643.98\n",
      "mean_7_62: 642.00\n",
      "mean_14_11: 622.94\n",
      "mean_14_32: 606.07\n",
      "mean_60_42: 583.78\n",
      "mean_7_02: 577.84\n",
      "mean_30_52: 547.35\n",
      "mean_140_11: 545.09\n",
      "mean_14_61: 532.35\n",
      "mean_30_51: 526.33\n",
      "mean_14_42: 516.81\n",
      "mean_30_32: 513.57\n",
      "mean_60_22: 497.95\n",
      "mean_14_62: 484.85\n",
      "mean_14_21: 480.31\n",
      "mean_140_52: 468.07\n",
      "mean_60_32: 443.43\n",
      "mean_60_52: 438.27\n",
      "mean_30_41: 419.99\n",
      "mean_30_21: 377.72\n",
      "mean_30_11: 349.18\n",
      "mean_60_51: 348.57\n",
      "mean_60_41: 338.79\n",
      "mean_60_31: 336.00\n",
      "aft_promo_014: 0.00\n",
      "aft_promo_060: 0.00\n",
      "aft_promo_0140: 0.00\n",
      "aft_promo_114: 0.00\n",
      "aft_promo_160: 0.00\n",
      "aft_promo_1140: 0.00\n",
      "aft_promo_214: 0.00\n",
      "aft_promo_260: 0.00\n",
      "aft_promo_2140: 0.00\n",
      "aft_promo_314: 0.00\n",
      "aft_promo_360: 0.00\n",
      "aft_promo_3140: 0.00\n",
      "aft_promo_414: 0.00\n",
      "aft_promo_460: 0.00\n",
      "aft_promo_4140: 0.00\n",
      "aft_promo_514: 0.00\n",
      "aft_promo_560: 0.00\n",
      "aft_promo_5140: 0.00\n",
      "aft_promo_614: 0.00\n",
      "aft_promo_660: 0.00\n",
      "aft_promo_6140: 0.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Step 14\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\ttraining's rmse: 0.611259\tvalid_1's rmse: 0.61877\n",
      "[200]\ttraining's rmse: 0.601133\tvalid_1's rmse: 0.61626\n",
      "[300]\ttraining's rmse: 0.594374\tvalid_1's rmse: 0.615258\n",
      "[400]\ttraining's rmse: 0.588439\tvalid_1's rmse: 0.615052\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[400]\ttraining's rmse: 0.588439\tvalid_1's rmse: 0.615052\n",
      "mean_30_01: 840763.31\n",
      "mean_30_61: 247440.26\n",
      "mean_14_01: 163092.56\n",
      "mean_7_01: 108288.79\n",
      "mean_3_01: 107338.08\n",
      "mean_60_01: 62405.74\n",
      "unpromo_14daysAfter: 42126.16\n",
      "promo_14days: 17868.68\n",
      "mean_3_12: 16826.78\n",
      "class: 15251.85\n",
      "mean_3_11: 13365.69\n",
      "promo_6: 12526.49\n",
      "mean_3_21: 10176.83\n",
      "family: 7405.52\n",
      "mean_140_01: 7370.56\n",
      "type: 6187.02\n",
      "mean_60_21: 5877.37\n",
      "mean_140_12: 5798.35\n",
      "promo_140days: 4964.81\n",
      "promo_60days: 4960.16\n",
      "city: 4480.47\n",
      "mean_140_22: 4281.20\n",
      "mean_60_12: 3478.09\n",
      "mean_3_61: 2837.49\n",
      "mean_60_11: 2813.82\n",
      "cluster: 2628.05\n",
      "mean_3_31: 2624.87\n",
      "mean_3_51: 2471.05\n",
      "mean_60_22: 2426.87\n",
      "mean_30_11: 2412.00\n",
      "promo_4: 2384.32\n",
      "mean_3_22: 2009.95\n",
      "mean_3_41: 1872.24\n",
      "promo_1: 1871.32\n",
      "mean_3_52: 1839.27\n",
      "mean_3_32: 1813.49\n",
      "state: 1796.26\n",
      "mean_3_02: 1776.66\n",
      "promo_3: 1748.45\n",
      "perishable: 1597.53\n",
      "mean_14_12: 1481.75\n",
      "mean_3_62: 1438.29\n",
      "mean_3_42: 1378.98\n",
      "mean_60_51: 1369.04\n",
      "mean_7_12: 1353.92\n",
      "mean_140_61: 1336.26\n",
      "mean_7_51: 1320.65\n",
      "mean_60_32: 1295.77\n",
      "mean_30_12: 1202.64\n",
      "mean_7_61: 1111.56\n",
      "promo_2: 1022.16\n",
      "mean_7_31: 997.06\n",
      "mean_30_22: 955.32\n",
      "promo_5: 938.51\n",
      "mean_140_32: 926.34\n",
      "mean_30_31: 902.52\n",
      "mean_7_52: 891.73\n",
      "mean_7_41: 882.32\n",
      "mean_7_02: 825.07\n",
      "mean_14_61: 812.75\n",
      "mean_7_22: 809.84\n",
      "mean_14_32: 796.94\n",
      "mean_7_62: 777.32\n",
      "mean_7_11: 757.04\n",
      "mean_7_42: 720.06\n",
      "mean_7_21: 682.00\n",
      "mean_14_22: 667.35\n",
      "mean_30_41: 657.37\n",
      "mean_140_51: 651.55\n",
      "mean_14_51: 651.41\n",
      "mean_14_42: 638.17\n",
      "mean_30_42: 632.74\n",
      "mean_14_41: 632.28\n",
      "mean_14_21: 612.38\n",
      "mean_14_52: 611.27\n",
      "mean_14_11: 605.46\n",
      "mean_7_32: 598.78\n",
      "mean_60_61: 590.71\n",
      "mean_30_21: 584.49\n",
      "mean_60_52: 584.10\n",
      "mean_14_62: 554.31\n",
      "mean_30_32: 546.02\n",
      "mean_60_02: 517.98\n",
      "mean_140_02: 517.34\n",
      "mean_60_42: 517.05\n",
      "mean_14_31: 507.24\n",
      "mean_30_02: 499.97\n",
      "mean_60_41: 499.31\n",
      "promo_0: 479.38\n",
      "mean_30_62: 463.02\n",
      "mean_140_42: 459.77\n",
      "mean_140_41: 446.67\n",
      "mean_14_02: 435.41\n",
      "mean_60_31: 430.04\n",
      "mean_60_62: 417.99\n",
      "mean_30_51: 417.55\n",
      "mean_30_52: 400.47\n",
      "mean_140_11: 320.02\n",
      "mean_140_62: 318.48\n",
      "mean_140_52: 315.79\n",
      "mean_140_31: 265.03\n",
      "mean_140_21: 145.10\n",
      "aft_promo_014: 0.00\n",
      "aft_promo_060: 0.00\n",
      "aft_promo_0140: 0.00\n",
      "aft_promo_114: 0.00\n",
      "aft_promo_160: 0.00\n",
      "aft_promo_1140: 0.00\n",
      "aft_promo_214: 0.00\n",
      "aft_promo_260: 0.00\n",
      "aft_promo_2140: 0.00\n",
      "aft_promo_314: 0.00\n",
      "aft_promo_360: 0.00\n",
      "aft_promo_3140: 0.00\n",
      "aft_promo_414: 0.00\n",
      "aft_promo_460: 0.00\n",
      "aft_promo_4140: 0.00\n",
      "aft_promo_514: 0.00\n",
      "aft_promo_560: 0.00\n",
      "aft_promo_5140: 0.00\n",
      "aft_promo_614: 0.00\n",
      "aft_promo_660: 0.00\n",
      "aft_promo_6140: 0.00\n",
      "==================================================\n",
      "Step 15\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\ttraining's rmse: 0.622541\tvalid_1's rmse: 0.629657\n",
      "[200]\ttraining's rmse: 0.612309\tvalid_1's rmse: 0.628322\n",
      "[300]\ttraining's rmse: 0.605718\tvalid_1's rmse: 0.627539\n",
      "[400]\ttraining's rmse: 0.599834\tvalid_1's rmse: 0.626861\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[400]\ttraining's rmse: 0.599834\tvalid_1's rmse: 0.626861\n",
      "mean_30_01: 652515.76\n",
      "mean_14_01: 411815.89\n",
      "mean_30_61: 266617.30\n",
      "mean_7_01: 138238.11\n",
      "mean_60_01: 89342.97\n",
      "unpromo_14daysAfter: 35302.21\n",
      "mean_3_22: 33391.01\n",
      "mean_3_21: 23381.39\n",
      "mean_3_01: 16560.38\n",
      "class: 15459.62\n",
      "mean_60_61: 14783.21\n",
      "promo_14days: 13050.32\n",
      "mean_60_21: 9928.00\n",
      "mean_140_01: 9485.72\n",
      "mean_140_12: 7131.82\n",
      "mean_60_41: 7118.81\n",
      "type: 5967.44\n",
      "mean_60_31: 5753.59\n",
      "family: 5468.33\n",
      "promo_60days: 5405.37\n",
      "promo_140days: 4454.99\n",
      "mean_140_61: 4281.03\n",
      "mean_60_12: 3548.26\n",
      "mean_60_22: 3422.86\n",
      "mean_3_12: 3340.41\n",
      "city: 3308.60\n",
      "cluster: 3230.36\n",
      "mean_140_21: 2976.71\n",
      "state: 2581.85\n",
      "mean_3_11: 2425.60\n",
      "mean_3_51: 2335.74\n",
      "mean_140_22: 2259.65\n",
      "mean_60_11: 2242.22\n",
      "mean_60_51: 2040.38\n",
      "mean_3_31: 2038.23\n",
      "mean_3_42: 1959.07\n",
      "mean_30_22: 1938.94\n",
      "mean_60_42: 1844.09\n",
      "mean_30_12: 1841.19\n",
      "mean_7_12: 1833.63\n",
      "mean_60_32: 1800.27\n",
      "mean_3_41: 1785.46\n",
      "mean_3_32: 1784.74\n",
      "mean_3_61: 1703.33\n",
      "mean_3_62: 1676.63\n",
      "mean_3_52: 1660.16\n",
      "perishable: 1498.36\n",
      "mean_3_02: 1403.58\n",
      "mean_14_12: 1365.04\n",
      "promo_4: 1250.71\n",
      "mean_7_51: 1245.50\n",
      "mean_140_51: 1239.45\n",
      "promo_1: 1185.21\n",
      "mean_30_11: 1132.19\n",
      "mean_7_21: 1123.06\n",
      "mean_7_62: 1045.06\n",
      "mean_140_11: 1026.78\n",
      "mean_7_02: 1026.33\n",
      "mean_7_11: 1019.69\n",
      "mean_140_52: 974.98\n",
      "promo_2: 949.40\n",
      "mean_30_42: 925.37\n",
      "mean_140_41: 884.33\n",
      "mean_7_61: 877.35\n",
      "mean_14_62: 861.38\n",
      "mean_7_32: 861.11\n",
      "mean_7_42: 858.28\n",
      "mean_7_41: 857.93\n",
      "mean_7_22: 855.31\n",
      "mean_14_11: 822.93\n",
      "mean_60_62: 807.49\n",
      "mean_140_02: 797.53\n",
      "mean_30_52: 794.89\n",
      "mean_7_31: 773.73\n",
      "mean_14_42: 742.51\n",
      "mean_7_52: 739.58\n",
      "promo_3: 722.71\n",
      "mean_30_41: 705.87\n",
      "mean_14_61: 697.34\n",
      "mean_14_41: 689.92\n",
      "mean_140_32: 689.56\n",
      "mean_14_02: 684.45\n",
      "mean_14_32: 672.50\n",
      "mean_14_22: 642.00\n",
      "mean_14_52: 638.81\n",
      "mean_140_42: 595.11\n",
      "mean_60_02: 584.56\n",
      "promo_6: 571.98\n",
      "mean_30_02: 541.30\n",
      "mean_14_21: 537.20\n",
      "mean_14_31: 520.83\n",
      "mean_14_51: 516.00\n",
      "mean_140_62: 515.53\n",
      "mean_60_52: 486.14\n",
      "mean_30_51: 470.50\n",
      "promo_5: 464.90\n",
      "mean_30_62: 452.36\n",
      "mean_30_32: 446.92\n",
      "mean_30_21: 432.54\n",
      "mean_30_31: 421.32\n",
      "mean_140_31: 331.33\n",
      "promo_0: 281.43\n",
      "aft_promo_014: 0.00\n",
      "aft_promo_060: 0.00\n",
      "aft_promo_0140: 0.00\n",
      "aft_promo_114: 0.00\n",
      "aft_promo_160: 0.00\n",
      "aft_promo_1140: 0.00\n",
      "aft_promo_214: 0.00\n",
      "aft_promo_260: 0.00\n",
      "aft_promo_2140: 0.00\n",
      "aft_promo_314: 0.00\n",
      "aft_promo_360: 0.00\n",
      "aft_promo_3140: 0.00\n",
      "aft_promo_414: 0.00\n",
      "aft_promo_460: 0.00\n",
      "aft_promo_4140: 0.00\n",
      "aft_promo_514: 0.00\n",
      "aft_promo_560: 0.00\n",
      "aft_promo_5140: 0.00\n",
      "aft_promo_614: 0.00\n",
      "aft_promo_660: 0.00\n",
      "aft_promo_6140: 0.00\n",
      "==================================================\n",
      "Step 16\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\ttraining's rmse: 0.629003\tvalid_1's rmse: 0.637413\n",
      "[200]\ttraining's rmse: 0.618154\tvalid_1's rmse: 0.634675\n",
      "[300]\ttraining's rmse: 0.610586\tvalid_1's rmse: 0.633467\n",
      "[400]\ttraining's rmse: 0.604212\tvalid_1's rmse: 0.632929\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[400]\ttraining's rmse: 0.604212\tvalid_1's rmse: 0.632929\n",
      "mean_14_01: 551746.71\n",
      "mean_30_01: 540393.32\n",
      "mean_30_61: 278660.22\n",
      "mean_60_01: 95525.33\n",
      "mean_7_01: 89903.32\n",
      "mean_3_31: 58112.84\n",
      "mean_3_32: 56403.16\n",
      "mean_60_41: 48592.61\n",
      "unpromo_14daysAfter: 36215.65\n",
      "mean_60_51: 25777.10\n",
      "mean_140_01: 18647.60\n",
      "class: 17566.43\n",
      "promo_14days: 14503.54\n",
      "type: 11246.42\n",
      "state: 10301.84\n",
      "mean_3_01: 9491.77\n",
      "mean_3_41: 6865.55\n",
      "city: 6683.73\n",
      "family: 6614.17\n",
      "cluster: 6290.82\n",
      "mean_140_12: 6233.14\n",
      "mean_3_22: 5568.01\n",
      "mean_30_31: 5265.93\n",
      "mean_30_32: 5095.61\n",
      "promo_60days: 4663.32\n",
      "mean_140_22: 4216.51\n",
      "promo_140days: 3906.25\n",
      "mean_3_42: 3641.36\n",
      "mean_60_31: 3454.44\n",
      "mean_7_12: 3408.74\n",
      "mean_30_22: 3256.57\n",
      "mean_140_61: 2971.09\n",
      "mean_60_22: 2810.89\n",
      "mean_60_21: 2809.77\n",
      "mean_3_12: 2705.44\n",
      "mean_3_52: 2460.70\n",
      "mean_3_21: 2443.89\n",
      "mean_60_12: 2306.76\n",
      "mean_30_21: 2263.91\n",
      "mean_3_11: 2251.76\n",
      "mean_3_51: 2170.12\n",
      "mean_3_61: 1960.37\n",
      "mean_60_42: 1872.37\n",
      "mean_3_02: 1869.19\n",
      "mean_14_12: 1709.67\n",
      "mean_3_62: 1705.21\n",
      "mean_140_42: 1418.69\n",
      "mean_140_32: 1344.57\n",
      "mean_30_12: 1321.48\n",
      "mean_140_31: 1312.35\n",
      "mean_60_32: 1246.78\n",
      "mean_7_22: 1246.70\n",
      "mean_140_51: 1239.53\n",
      "mean_7_32: 1200.11\n",
      "mean_60_52: 1088.92\n",
      "mean_7_51: 1054.83\n",
      "mean_7_42: 1054.41\n",
      "mean_140_62: 1019.91\n",
      "mean_140_11: 1009.04\n",
      "mean_14_02: 990.38\n",
      "mean_30_42: 975.44\n",
      "mean_30_11: 968.42\n",
      "mean_30_02: 966.04\n",
      "mean_7_61: 943.20\n",
      "mean_7_02: 925.42\n",
      "mean_7_11: 911.16\n",
      "mean_7_52: 891.84\n",
      "mean_60_61: 891.40\n",
      "mean_140_02: 874.64\n",
      "mean_14_22: 855.68\n",
      "mean_30_41: 828.58\n",
      "mean_14_62: 819.95\n",
      "mean_7_41: 815.12\n",
      "mean_7_31: 809.43\n",
      "mean_14_32: 765.89\n",
      "mean_14_11: 759.53\n",
      "mean_7_21: 737.51\n",
      "promo_4: 706.35\n",
      "mean_14_51: 705.27\n",
      "promo_3: 698.58\n",
      "mean_7_62: 696.56\n",
      "mean_14_31: 694.06\n",
      "mean_30_62: 682.38\n",
      "mean_14_52: 677.85\n",
      "mean_30_51: 664.35\n",
      "mean_14_61: 646.84\n",
      "promo_6: 603.90\n",
      "mean_140_21: 593.87\n",
      "mean_60_11: 560.21\n",
      "mean_140_52: 540.48\n",
      "promo_1: 534.60\n",
      "mean_60_62: 528.65\n",
      "mean_14_21: 521.85\n",
      "mean_14_42: 485.04\n",
      "mean_140_41: 455.31\n",
      "mean_14_41: 422.08\n",
      "mean_30_52: 410.41\n",
      "promo_0: 375.87\n",
      "mean_60_02: 374.89\n",
      "perishable: 368.75\n",
      "promo_5: 345.25\n",
      "promo_2: 330.61\n",
      "aft_promo_014: 0.00\n",
      "aft_promo_060: 0.00\n",
      "aft_promo_0140: 0.00\n",
      "aft_promo_114: 0.00\n",
      "aft_promo_160: 0.00\n",
      "aft_promo_1140: 0.00\n",
      "aft_promo_214: 0.00\n",
      "aft_promo_260: 0.00\n",
      "aft_promo_2140: 0.00\n",
      "aft_promo_314: 0.00\n",
      "aft_promo_360: 0.00\n",
      "aft_promo_3140: 0.00\n",
      "aft_promo_414: 0.00\n",
      "aft_promo_460: 0.00\n",
      "aft_promo_4140: 0.00\n",
      "aft_promo_514: 0.00\n",
      "aft_promo_560: 0.00\n",
      "aft_promo_5140: 0.00\n",
      "aft_promo_614: 0.00\n",
      "aft_promo_660: 0.00\n",
      "aft_promo_6140: 0.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation msre: 0.378200033302\n"
     ]
    }
   ],
   "source": [
    "val_pred = []\n",
    "for i in range(16):\n",
    "    print(\"=\" * 50)\n",
    "    print(\"Step %d\" % (i+1))\n",
    "    print(\"=\" * 50)\n",
    "    dtrain = lgb.Dataset(\n",
    "        X_train, y_train[:,i].reshape(X_train.shape[0]),\n",
    "        weight=X_train[\"perishable\"] * 0.25 + 1\n",
    "    )\n",
    "    dval = lgb.Dataset(\n",
    "        X_val, y_val[:,i].reshape(X_val.shape[0]), reference=lgb_train, \n",
    "        weight=X_val.perishable.values * 0.25 + 1\n",
    "        )\n",
    "    bst = lgb.train(\n",
    "        params, dtrain, num_boost_round=MAX_ROUNDS,\n",
    "        valid_sets=[dtrain, dval], early_stopping_rounds=50, verbose_eval=100\n",
    "    )\n",
    "    print(\"\\n\".join((\"%s: %.2f\" % x) for x in sorted(\n",
    "        zip(X_train.columns, bst.feature_importance(\"gain\")),\n",
    "        key=lambda x: x[1], reverse=True\n",
    "    )))\n",
    "    val_pred.append(bst.predict(\n",
    "        X_val, num_iteration=bst.best_iteration or MAX_ROUNDS))\n",
    "    \n",
    "assert y_val.shape == np.array(val_pred).transpose().shape\n",
    "print(\"Validation msre:\", mean_squared_error(y_val, np.array(val_pred).transpose()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation mse: 0.378200033302\n",
      "nwrmsle = 0.6156949436893447\n"
     ]
    }
   ],
   "source": [
    "print(\"Validation mse:\", mean_squared_error(y_val, np.array(val_pred).transpose()))\n",
    "weight = X_val[\"perishable\"] * 0.25 + 1\n",
    "err = (y_val - np.array(val_pred).transpose())**2\n",
    "err = err.sum(axis=1) * weight\n",
    "err = np.sqrt(err.sum() / weight.sum() / 16)\n",
    "print('nwrmsle = {}'.format(err))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
